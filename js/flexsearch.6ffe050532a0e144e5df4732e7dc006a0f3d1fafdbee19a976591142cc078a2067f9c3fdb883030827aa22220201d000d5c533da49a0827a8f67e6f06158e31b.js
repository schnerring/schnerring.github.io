(()=>{var ne=Object.create;var ee=Object.defineProperty;var ie=Object.getOwnPropertyDescriptor;var se=Object.getOwnPropertyNames;var ae=Object.getPrototypeOf,ue=Object.prototype.hasOwnProperty;var le=e=>ee(e,"__esModule",{value:!0});var ce=(e,r)=>()=>(r||e((r={exports:{}}).exports,r),r.exports);var he=(e,r,o)=>{if(r&&typeof r=="object"||typeof r=="function")for(let n of se(r))!ue.call(e,n)&&n!=="default"&&ee(e,n,{get:()=>r[n],enumerable:!(o=ie(r,n))||o.enumerable});return e},de=e=>he(le(ee(e!=null?ne(ae(e)):{},"default",e&&e.__esModule&&"default"in e?{get:()=>e.default,enumerable:!0}:{value:e,enumerable:!0})),e);var re=ce((exports,module)=>{(function _f(self){"use strict";try{module&&(self=module)}catch(e){}self._factory=_f;var t;function u(e){return typeof e!="undefined"?e:!0}function aa(e){let r=Array(e);for(let o=0;o<e;o++)r[o]=v();return r}function v(){return Object.create(null)}function ba(e,r){return r.length-e.length}function x(e){return typeof e=="string"}function C(e){return typeof e=="object"}function D(e){return typeof e=="function"}function ca(e,r){var o=da;if(e&&(r&&(e=E(e,r)),this.H&&(e=E(e,this.H)),this.J&&1<e.length&&(e=E(e,this.J)),o||o==="")){if(e=e.split(o),this.filter){r=this.filter,o=e.length;let n=[];for(let i=0,s=0;i<o;i++){let l=e[i];l&&!r[l]&&(n[s++]=l)}e=n}return e}return e}let da=/[\p{Z}\p{S}\p{P}\p{C}]+/u,ea=/[\u0300-\u036f]/g;function fa(e,r){let o=Object.keys(e),n=o.length,i=[],s="",l=0;for(let h=0,m,g;h<n;h++)m=o[h],(g=e[m])?(i[l++]=F(r?"(?!\\b)"+m+"(\\b|_)":m),i[l++]=g):s+=(s?"|":"")+m;return s&&(i[l++]=F(r?"(?!\\b)("+s+")(\\b|_)":"("+s+")"),i[l]=""),i}function E(e,r){for(let o=0,n=r.length;o<n&&(e=e.replace(r[o],r[o+1]),e);o+=2);return e}function F(e){return new RegExp(e,"g")}function ha(e){let r="",o="";for(let n=0,i=e.length,s;n<i;n++)(s=e[n])!==o&&(r+=o=s);return r}var ja={encode:ia,F:!1,G:""};function ia(e){return ca.call(this,(""+e).toLowerCase(),!1)}let ka={},G={};function la(e){I(e,"add"),I(e,"append"),I(e,"search"),I(e,"update"),I(e,"remove")}function I(e,r){e[r+"Async"]=function(){let o=this,n=arguments;var i=n[n.length-1];let s;return D(i)&&(s=i,delete n[n.length-1]),i=new Promise(function(l){setTimeout(function(){o.async=!0;let h=o[r].apply(o,n);o.async=!1,l(h)})}),s?(i.then(s),this):i}}function ma(e,r,o,n){let i=e.length,s=[],l,h,m=0;n&&(n=[]);for(let g=i-1;0<=g;g--){let f=e[g],_=f.length,w=v(),k=!l;for(let p=0;p<_;p++){let y=f[p],q=y.length;if(q)for(let z=0,R,A;z<q;z++)if(A=y[z],l){if(l[A]){if(!g){if(o)o--;else if(s[m++]=A,m===r)return s}(g||n)&&(w[A]=1),k=!0}if(n&&(h[A]=(R=h[A])?++R:R=1,R<i)){let B=n[R-2]||(n[R-2]=[]);B[B.length]=A}}else w[A]=1}if(n)l||(h=w);else if(!k)return[];l=w}if(n)for(let g=n.length-1,f,_;0<=g;g--){f=n[g],_=f.length;for(let w=0,k;w<_;w++)if(k=f[w],!l[k]){if(o)o--;else if(s[m++]=k,m===r)return s;l[k]=1}}return s}function na(e,r){let o=v(),n=v(),i=[];for(let s=0;s<e.length;s++)o[e[s]]=1;for(let s=0,l;s<r.length;s++){l=r[s];for(let h=0,m;h<l.length;h++)m=l[h],o[m]&&!n[m]&&(n[m]=1,i[i.length]=m)}return i}function J(e){this.l=e!==!0&&e,this.cache=v(),this.h=[]}function oa(e,r,o){C(e)&&(e=e.query);let n=this.cache.get(e);return n||(n=this.search(e,r,o),this.cache.set(e,n)),n}J.prototype.set=function(e,r){if(!this.cache[e]){var o=this.h.length;for(o===this.l?delete this.cache[this.h[o-1]]:o++,--o;0<o;o--)this.h[o]=this.h[o-1];this.h[0]=e}this.cache[e]=r},J.prototype.get=function(e){let r=this.cache[e];if(this.l&&r&&(e=this.h.indexOf(e))){let o=this.h[e-1];this.h[e-1]=this.h[e],this.h[e]=o}return r};let qa={memory:{charset:"latin:extra",D:3,B:4,m:!1},performance:{D:3,B:3,s:!1,context:{depth:2,D:1}},match:{charset:"latin:extra",G:"reverse"},score:{charset:"latin:advanced",D:20,B:3,context:{depth:3,D:9}},default:{}};function ra(e,r,o,n,i,s){setTimeout(function(){let l=e(o,JSON.stringify(s));l&&l.then?l.then(function(){r.export(e,r,o,n,i+1)}):r.export(e,r,o,n,i+1)})}function K(e,r){if(!(this instanceof K))return new K(e);var o;if(e){x(e)?e=qa[e]:(o=e.preset)&&(e=Object.assign({},o[o],e)),o=e.charset;var n=e.lang;x(o)&&(o.indexOf(":")===-1&&(o+=":default"),o=G[o]),x(n)&&(n=ka[n])}else e={};let i,s,l=e.context||{};if(this.encode=e.encode||o&&o.encode||ia,this.register=r||v(),this.D=i=e.resolution||9,this.G=r=o&&o.G||e.tokenize||"strict",this.depth=r==="strict"&&l.depth,this.l=u(l.bidirectional),this.s=s=u(e.optimize),this.m=u(e.fastupdate),this.B=e.minlength||1,this.C=e.boost,this.map=s?aa(i):v(),this.A=i=l.resolution||1,this.h=s?aa(i):v(),this.F=o&&o.F||e.rtl,this.H=(r=e.matcher||n&&n.H)&&fa(r,!1),this.J=(r=e.stemmer||n&&n.J)&&fa(r,!0),o=r=e.filter||n&&n.filter){o=r,n=v();for(let h=0,m=o.length;h<m;h++)n[o[h]]=1;o=n}this.filter=o,this.cache=(r=e.cache)&&new J(r)}t=K.prototype,t.append=function(e,r){return this.add(e,r,!0)},t.add=function(e,r,o,n){if(r&&(e||e===0)){if(!n&&!o&&this.register[e])return this.update(e,r);if(r=this.encode(r),n=r.length){let g=v(),f=v(),_=this.depth,w=this.D;for(let k=0;k<n;k++){let p=r[this.F?n-1-k:k];var i=p.length;if(p&&i>=this.B&&(_||!f[p])){var s=L(w,n,k),l="";switch(this.G){case"full":if(3<i){for(s=0;s<i;s++)for(var h=i;h>s;h--)if(h-s>=this.B){var m=L(w,n,k,i,s);l=p.substring(s,h),M(this,f,l,m,e,o)}break}case"reverse":if(2<i){for(h=i-1;0<h;h--)l=p[h]+l,l.length>=this.B&&M(this,f,l,L(w,n,k,i,h),e,o);l=""}case"forward":if(1<i){for(h=0;h<i;h++)l+=p[h],l.length>=this.B&&M(this,f,l,s,e,o);break}default:if(this.C&&(s=Math.min(s/this.C(r,p,k)|0,w-1)),M(this,f,p,s,e,o),_&&1<n&&k<n-1){for(i=v(),l=this.A,s=p,h=Math.min(_+1,n-k),i[s]=1,m=1;m<h;m++)if((p=r[this.F?n-1-k-m:k+m])&&p.length>=this.B&&!i[p]){i[p]=1;let y=this.l&&p>s;M(this,g,y?s:p,L(l+(n/2>l?0:1),n,k,h-1,m-1),e,o,y?p:s)}}}}}this.m||(this.register[e]=1)}}return this};function L(e,r,o,n,i){return o&&1<e?r+(n||0)<=e?o+(i||0):(e-1)/(r+(n||0))*(o+(i||0))+1|0:0}function M(e,r,o,n,i,s,l){let h=l?e.h:e.map;(!r[o]||l&&!r[o][l])&&(e.s&&(h=h[n]),l?(r=r[o]||(r[o]=v()),r[l]=1,h=h[l]||(h[l]=v())):r[o]=1,h=h[o]||(h[o]=[]),e.s||(h=h[n]||(h[n]=[])),s&&h.indexOf(i)!==-1||(h[h.length]=i,e.m&&(e=e.register[i]||(e.register[i]=[]),e[e.length]=h)))}t.search=function(e,r,o){o||(!r&&C(e)?(o=e,e=o.query):C(r)&&(o=r));let n=[],i,s,l=0;if(o){r=o.limit,l=o.offset||0;var h=o.context;s=o.suggest}if(e&&(e=this.encode(e),i=e.length,1<i)){o=v();var m=[];for(let f=0,_=0,w;f<i;f++)if((w=e[f])&&w.length>=this.B&&!o[w])if(this.s||s||this.map[w])m[_++]=w,o[w]=1;else return n;e=m,i=e.length}if(!i)return n;r||(r=100),h=this.depth&&1<i&&h!==!1,o=0;let g;h?(g=e[0],o=1):1<i&&e.sort(ba);for(let f,_;o<i;o++){if(_=e[o],h?(f=sa(this,n,s,r,l,i===2,_,g),s&&f===!1&&n.length||(g=_)):f=sa(this,n,s,r,l,i===1,_),f)return f;if(s&&o===i-1){if(m=n.length,!m){if(h){h=0,o=-1;continue}return n}if(m===1)return ta(n[0],r,l)}}return ma(n,r,l,s)};function sa(e,r,o,n,i,s,l,h){let m=[],g=h?e.h:e.map;if(e.s||(g=ua(g,l,h,e.l)),g){let f=0,_=Math.min(g.length,h?e.A:e.D);for(let w=0,k=0,p,y;w<_&&!((p=g[w])&&(e.s&&(p=ua(p,l,h,e.l)),i&&p&&s&&(y=p.length,y<=i?(i-=y,p=null):(p=p.slice(i),i=0)),p&&(m[f++]=p,s&&(k+=p.length,k>=n))));w++);if(f){if(s)return ta(m,n,0);r[r.length]=m;return}}return!o&&m}function ta(e,r,o){return e=e.length===1?e[0]:[].concat.apply([],e),o||e.length>r?e.slice(o,o+r):e}function ua(e,r,o,n){return o?(n=n&&r>o,e=(e=e[n?r:o])&&e[n?o:r]):e=e[r],e}t.contain=function(e){return!!this.register[e]},t.update=function(e,r){return this.remove(e).add(e,r)},t.remove=function(e,r){let o=this.register[e];if(o){if(this.m)for(let n=0,i;n<o.length;n++)i=o[n],i.splice(i.indexOf(e),1);else N(this.map,e,this.D,this.s),this.depth&&N(this.h,e,this.A,this.s);if(r||delete this.register[e],this.cache){r=this.cache;for(let n=0,i,s;n<r.h.length;n++)s=r.h[n],i=r.cache[s],i.indexOf(e)!==-1&&(r.h.splice(n--,1),delete r.cache[s])}}return this};function N(e,r,o,n,i){let s=0;if(e.constructor===Array)if(i)r=e.indexOf(r),r!==-1?1<e.length&&(e.splice(r,1),s++):s++;else{i=Math.min(e.length,o);for(let l=0,h;l<i;l++)(h=e[l])&&(s=N(h,r,o,n,i),n||s||delete e[l])}else for(let l in e)(s=N(e[l],r,o,n,i))||delete e[l];return s}t.searchCache=oa,t.export=function(e,r,o,n,i){let s,l;switch(i||(i=0)){case 0:if(s="reg",this.m){l=v();for(let h in this.register)l[h]=1}else l=this.register;break;case 1:s="cfg",l={doc:0,opt:this.s?1:0};break;case 2:s="map",l=this.map;break;case 3:s="ctx",l=this.h;break;default:return}return ra(e,r||this,o?o+"."+s:s,n,i,l),!0},t.import=function(e,r){if(r)switch(x(r)&&(r=JSON.parse(r)),e){case"cfg":this.s=!!r.opt;break;case"reg":this.m=!1,this.register=r;break;case"map":this.map=r;break;case"ctx":this.h=r}},la(K.prototype);function va(e){e=e.data;var r=self._index;let o=e.args;var n=e.task;switch(n){case"init":n=e.options||{},e=e.factory,r=n.encode,n.cache=!1,r&&r.indexOf("function")===0&&(n.encode=Function("return "+r)()),e?(Function("return "+e)()(self),self._index=new self.FlexSearch.Index(n),delete self.FlexSearch):self._index=new K(n);break;default:e=e.id,r=r[n].apply(r,o),postMessage(n==="search"?{id:e,msg:r}:{id:e})}}let wa=0;function O(e){if(!(this instanceof O))return new O(e);var r;e?D(r=e.encode)&&(e.encode=r.toString()):e={},(r=(self||window)._factory)&&(r=r.toString());let o=self.exports,n=this;this.o=xa(r,o,e.worker),this.h=v(),this.o&&(o?this.o.on("message",function(i){n.h[i.id](i.msg),delete n.h[i.id]}):this.o.onmessage=function(i){i=i.data,n.h[i.id](i.msg),delete n.h[i.id]},this.o.postMessage({task:"init",factory:r,options:e}))}P("add"),P("append"),P("search"),P("update"),P("remove");function P(e){O.prototype[e]=O.prototype[e+"Async"]=function(){let r=this,o=[].slice.call(arguments);var n=o[o.length-1];let i;return D(n)&&(i=n,o.splice(o.length-1,1)),n=new Promise(function(s){setTimeout(function(){r.h[++wa]=s,r.o.postMessage({task:e,id:wa,args:o})})}),i?(n.then(i),this):n}}function xa(a,b,c){let d;try{d=b?eval('new (require("worker_threads")["Worker"])("../dist/node/node.js")'):a?new Worker(URL.createObjectURL(new Blob(["onmessage="+va.toString()],{type:"text/javascript"}))):new Worker(x(c)?c:"worker/worker.js",{type:"module"})}catch(e){}return d}function Q(e){if(!(this instanceof Q))return new Q(e);var r=e.document||e.doc||e,o;this.K=[],this.h=[],this.A=[],this.register=v(),this.key=(o=r.key||r.id)&&S(o,this.A)||"id",this.m=u(e.fastupdate),this.C=(o=r.store)&&o!==!0&&[],this.store=o&&v(),this.I=(o=r.tag)&&S(o,this.A),this.l=o&&v(),this.cache=(o=e.cache)&&new J(o),e.cache=!1,this.o=e.worker,this.async=!1,o=v();let n=r.index||r.field||r;x(n)&&(n=[n]);for(let i=0,s,l;i<n.length;i++)s=n[i],x(s)||(l=s,s=s.field),l=C(l)?Object.assign({},e,l):e,this.o&&(o[s]=new O(l),o[s].o||(this.o=!1)),this.o||(o[s]=new K(l,this.register)),this.K[i]=S(s,this.A),this.h[i]=s;if(this.C)for(e=r.store,x(e)&&(e=[e]),r=0;r<e.length;r++)this.C[r]=S(e[r],this.A);this.index=o}function S(e,r){let o=e.split(":"),n=0;for(let i=0;i<o.length;i++)e=o[i],0<=e.indexOf("[]")&&(e=e.substring(0,e.length-2))&&(r[n]=!0),e&&(o[n++]=e);return n<o.length&&(o.length=n),1<n?o:o[0]}function T(e,r){if(x(r))e=e[r];else for(let o=0;e&&o<r.length;o++)e=e[r[o]];return e}function U(e,r,o,n,i){if(e=e[i],n===o.length-1)r[i]=e;else if(e)if(e.constructor===Array)for(r=r[i]=Array(e.length),i=0;i<e.length;i++)U(e,r,o,n,i);else r=r[i]||(r[i]=v()),i=o[++n],U(e,r,o,n,i)}function V(e,r,o,n,i,s,l,h){if(e=e[l])if(n===r.length-1){if(e.constructor===Array){if(o[n]){for(r=0;r<e.length;r++)i.add(s,e[r],!0,!0);return}e=e.join(" ")}i.add(s,e,h,!0)}else if(e.constructor===Array)for(l=0;l<e.length;l++)V(e,r,o,n,i,s,l,h);else l=r[++n],V(e,r,o,n,i,s,l,h)}t=Q.prototype,t.add=function(e,r,o){if(C(e)&&(r=e,e=T(r,this.key)),r&&(e||e===0)){if(!o&&this.register[e])return this.update(e,r);for(let n=0,i,s;n<this.h.length;n++)s=this.h[n],i=this.K[n],x(i)&&(i=[i]),V(r,i,this.A,0,this.index[s],e,i[0],o);if(this.I){let n=T(r,this.I),i=v();x(n)&&(n=[n]);for(let s=0,l,h;s<n.length;s++)if(l=n[s],!i[l]&&(i[l]=1,h=this.l[l]||(this.l[l]=[]),!o||h.indexOf(e)===-1)&&(h[h.length]=e,this.m)){let m=this.register[e]||(this.register[e]=[]);m[m.length]=h}}if(this.store&&(!o||!this.store[e])){let n;if(this.C){n=v();for(let i=0,s;i<this.C.length;i++)s=this.C[i],x(s)?n[s]=r[s]:U(r,n,s,0,s[0])}this.store[e]=n||r}}return this},t.append=function(e,r){return this.add(e,r,!0)},t.update=function(e,r){return this.remove(e).add(e,r)},t.remove=function(e){if(C(e)&&(e=T(e,this.key)),this.register[e]){for(var r=0;r<this.h.length&&(this.index[this.h[r]].remove(e,!this.o),!this.m);r++);if(this.I&&!this.m)for(let o in this.l){r=this.l[o];let n=r.indexOf(e);n!==-1&&(1<r.length?r.splice(n,1):delete this.l[o])}this.store&&delete this.store[e],delete this.register[e]}return this},t.search=function(e,r,o,n){o||(!r&&C(e)?(o=e,e=o.query):C(r)&&(o=r,r=0));let i=[],s=[],l,h,m,g,f,_,w=0;if(o)if(o.constructor===Array)m=o,o=null;else{if(m=(l=o.pluck)||o.index||o.field,g=o.tag,h=this.store&&o.enrich,f=o.bool==="and",r=o.limit||100,_=o.offset||0,g&&(x(g)&&(g=[g]),!e)){for(let p=0,y;p<g.length;p++)(y=ya.call(this,g[p],r,_,h))&&(i[i.length]=y,w++);return w?i:[]}x(m)&&(m=[m])}m||(m=this.h),f=f&&(1<m.length||g&&1<g.length);let k=!n&&(this.o||this.async)&&[];for(let p=0,y,q,z;p<m.length;p++){let R;if(q=m[p],x(q)||(R=q,q=q.field),k)k[p]=this.index[q].searchAsync(e,r,R||o);else{if(n?y=n[p]:y=this.index[q].search(e,r,R||o),z=y&&y.length,g&&z){let A=[],B=0;f&&(A[0]=[y]);for(let X=0,te,j;X<g.length;X++)te=g[X],(z=(j=this.l[te])&&j.length)&&(B++,A[A.length]=f?[j]:j);B&&(y=f?ma(A,r||100,_||0):na(y,A),z=y.length)}if(z)s[w]=q,i[w++]=y;else if(f)return[]}}if(k){let p=this;return new Promise(function(y){Promise.all(k).then(function(q){y(p.search(e,r,o,q))})})}if(!w)return[];if(l&&(!h||!this.store))return i[0];for(let p=0,y;p<s.length;p++){if(y=i[p],y.length&&h&&(y=za.call(this,y)),l)return y;i[p]={field:s[p],result:y}}return i};function ya(e,r,o,n){let i=this.l[e],s=i&&i.length-o;if(s&&0<s)return(s>r||o)&&(i=i.slice(o,o+r)),n&&(i=za.call(this,i)),{tag:e,result:i}}function za(e){let r=Array(e.length);for(let o=0,n;o<e.length;o++)n=e[o],r[o]={id:n,doc:this.store[n]};return r}t.contain=function(e){return!!this.register[e]},t.get=function(e){return this.store[e]},t.set=function(e,r){return this.store[e]=r,this},t.searchCache=oa,t.export=function(e,r,o,n,i){if(i||(i=0),n||(n=0),n<this.h.length){let s=this.h[n],l=this.index[s];r=this,setTimeout(function(){l.export(e,r,i?s.replace(":","-"):"",n,i++)||(n++,i=1,r.export(e,r,s,n,i))})}else{let s;switch(i){case 1:o="tag",s=this.l;break;case 2:o="store",s=this.store;break;default:return}ra(e,this,o,n,i,s)}},t.import=function(e,r){if(r)switch(x(r)&&(r=JSON.parse(r)),e){case"tag":this.l=r;break;case"reg":this.m=!1,this.register=r;for(let n=0,i;n<this.h.length;n++)i=this.index[this.h[n]],i.register=r,i.m=!1;break;case"store":this.store=r;break;default:e=e.split(".");let o=e[0];e=e[1],o&&e&&this.index[o].import(e,r)}},la(Q.prototype);var Ba={encode:Aa,F:!1,G:""};let Ca=[F("[\xE0\xE1\xE2\xE3\xE4\xE5]"),"a",F("[\xE8\xE9\xEA\xEB]"),"e",F("[\xEC\xED\xEE\xEF]"),"i",F("[\xF2\xF3\xF4\xF5\xF6\u0151]"),"o",F("[\xF9\xFA\xFB\xFC\u0171]"),"u",F("[\xFD\u0177\xFF]"),"y",F("\xF1"),"n",F("[\xE7c]"),"k",F("\xDF"),"s",F(" & ")," and "];function Aa(e){var r=e;return r.normalize&&(r=r.normalize("NFD").replace(ea,"")),ca.call(this,r.toLowerCase(),!e.normalize&&Ca)}var Ea={encode:Da,F:!1,G:"strict"};let Fa=/[^a-z0-9]+/,Ga={b:"p",v:"f",w:"f",z:"s",x:"s",\u00DF:"s",d:"t",n:"m",c:"k",g:"k",j:"k",q:"k",i:"e",y:"e",u:"o"};function Da(e){e=Aa.call(this,e).join(" ");let r=[];if(e){let o=e.split(Fa),n=o.length;for(let i=0,s,l=0;i<n;i++)if((e=o[i])&&(!this.filter||!this.filter[e])){s=e[0];let h=Ga[s]||s,m=h;for(let g=1;g<e.length;g++){s=e[g];let f=Ga[s]||s;f&&f!==m&&(h+=f,m=f)}r[l++]=h}}return r}var Ia={encode:Ha,F:!1,G:""};let Ja=[F("ae"),"a",F("oe"),"o",F("sh"),"s",F("th"),"t",F("ph"),"f",F("pf"),"f",F("(?![aeo])h(?![aeo])"),"",F("(?!^[aeo])h(?!^[aeo])"),""];function Ha(e,r){return e&&(e=Da.call(this,e).join(" "),2<e.length&&(e=E(e,Ja)),r||(1<e.length&&(e=ha(e)),e&&(e=e.split(" ")))),e}var La={encode:Ka,F:!1,G:""};let Ma=F("(?!\\b)[aeo]");function Ka(e){return e&&(e=Ha.call(this,e,!0),1<e.length&&(e=e.replace(Ma,"")),1<e.length&&(e=ha(e)),e&&(e=e.split(" "))),e}G["latin:default"]=ja,G["latin:simple"]=Ba,G["latin:balance"]=Ea,G["latin:advanced"]=Ia,G["latin:extra"]=La;let W=self,Y,Z={Index:K,Document:Q,Worker:O,registerCharset:function(e,r){G[e]=r},registerLanguage:function(e,r){ka[e]=r}};(Y=W.define)&&Y.amd?Y([],function(){return Z}):W.exports?W.exports=Z:W.FlexSearch=Z})(exports)});var oe=de(re());var $=document.getElementById("search__text"),H=document.getElementById("search__suggestions");$!==null&&document.addEventListener("keydown",e=>{e.ctrlKey&&e.key==="/"?(e.preventDefault(),$.focus()):e.key==="Escape"&&($.blur(),H.classList.add("search__suggestions--hidden"))});document.addEventListener("click",e=>{H.contains(e.target)||H.classList.add("search__suggestions--hidden")});document.addEventListener("keydown",e=>{if(H.classList.contains("search__suggestions--hidden"))return;let o=[...H.querySelectorAll("a")];if(o.length===0)return;let n=o.indexOf(document.activeElement);if(e.key==="ArrowDown"){e.preventDefault();let i=n+1<o.length?n+1:n;o[i].focus()}else e.key==="ArrowUp"&&(e.preventDefault(),nextIndex=n>0?n-1:0,o[nextIndex].focus())});(function(){let e=new oe.Document({tokenize:"forward",cache:100,document:{id:"id",store:["href","title","description"],index:["title","description","content"]}});e.add({id:0,href:"/posts/install-the-ubiquiti-unifi-controller-software-v6-inside-a-truenas-jail/",title:"Install the Ubiquiti Unifi Controller Software v6 Inside a TrueNAS Jail",description:`To manage Ubiquiti UniFi devices, a UniFi controller is required. Over a year ago, I initially installed the controller software inside a Ubuntu VirtualBox VM. Now that version 6 of the UniFi controller software is released, it&rsquo;s time to upgrade. I decided to reinstall the controller inside a TrueNAS jail instead of a VirtualBox VM. When searching the interwebs, I only found lots of outdated instructions. It turns out that it&rsquo;s very straightforward, so here are my quick notes on how to do it.
`,content:`To manage Ubiquiti UniFi devices, a UniFi controller is required. Over a year ago, I initially installed the controller software inside a Ubuntu VirtualBox VM. Now that version 6 of the UniFi controller software is released, it&rsquo;s time to upgrade. I decided to reinstall the controller inside a TrueNAS jail instead of a VirtualBox VM. When searching the interwebs, I only found lots of outdated instructions. It turns out that it&rsquo;s very straightforward, so here are my quick notes on how to do it.
I tested the following on TrueNAS version 12.0-U6.
Install UniFi #  Connect to a shell via Web GUI or SSH and fetch the latest FreeBSD release available. At the time of this writing, it was 12.2-RELEASE.
 iocage fetch   Connect to TrueNAS via shell and create the jail.
 iocage create --name unifi --release 12.2-RELEASE dhcp=1 boot=1   I use DHCP reservations to manage my server IPs. Setting dhcp=1 also sets vnet=1 and bpf=1. Network configuration is out of scope for this guide. Please consult the iocage manual (man iocage) or the TrueNAS jails documentation for more info. Setting boot=1 enables auto-start at boot time.
Connect to the jail.
 sudo iocage console unifi   Once connected, run the following commands.
 pkg update && pkg upgrade -y # install updates pkg install unifi6 # install unifi sysrc unifi_enable=YES # auto-start at boot service unifi start # start unifi   Connect to the UniFi controller at https://&lt;jail IP&gt;:8443.
Updating #  Updating requires very few steps. Please backup the jail before updating to be able to roll back if something goes wrong.
Connect to the jail.
 sudo iocage console unifi   Once connected, run the following commands.
 service unifi stop # stop unifi pkg update && pkg upgrade -y # install updates service unifi start # start unifi   And that&rsquo;s it!
`}).add({id:1,href:"/posts/use-custom-dns-servers-with-mullvad-and-any-wireguard-client/",title:"Use Custom DNS Servers With Mullvad And Any WireGuard Client",description:`I&rsquo;ve been using Mullvad VPN for a while now but only ever used it with the official client on my workstation. I use DNS extensively in my home network, so as soon as I activate Mullvad, I can&rsquo;t resolve DNS names locally. Of course, this is by design and expected. I own an OPNsense appliance, so the natural solution is to move the tunnel there.
TL;DR #  Use the following shell command to request an IP with no DNS hijacking:`,content:`I&rsquo;ve been using Mullvad VPN for a while now but only ever used it with the official client on my workstation. I use DNS extensively in my home network, so as soon as I activate Mullvad, I can&rsquo;t resolve DNS names locally. Of course, this is by design and expected. I own an OPNsense appliance, so the natural solution is to move the tunnel there.
TL;DR #  Use the following shell command to request an IP with no DNS hijacking:
curl -sSL https://api.mullvad.net/app/v1/wireguard-keys \\  -H &#34;Content-Type: application/json&#34; \\  -H &#34;Authorization: Token YOURMULLVADACCOUNTNUMBER&#34; \\  -d &#39;{&#34;pubkey&#34;:&#34;YOURWIREGUARDPUBLICKEY&#34;}&#39; Mullvad Hijacks DNS Queries Over WireGuard Tunnels #  Instead of using the OpenVPN protocol, I decided to go with the latest and greatest: WireGuard. OPNsense is a fork of FreeBSD but lacks a kernel implementation of WireGuard, requiring a plugin. It&rsquo;s good enough for me to try, and I hope WireGuard will be natively supported soon.
During my research on how to best configure this, there seemed to be the caveat of Mullvad hijacking DNS traffic going through WireGuard tunnels, redirecting it to their DNS servers. It decreases the likelihood of DNS leaks, but power users like you and I might not want that. What if I want to query DNS root servers through the VPN tunnel because I use my own DNS resolver? Mullvad hijacking DNS queries would make my DNS resolver trip up.
What a bummer, right? Looking at the Mullvad FAQ, it seemed the only solution was to resort to OpenVPN:
 Ports 1400 UDP and 1401 TCP do not have DNS hijacking enabled, which might work better for pfSense users
 But Mullvad launched support for custom DNS servers on the Mullvad VPN app back in April 2021. It also works for WireGuard, so what&rsquo;s the secret?
Reverse-engineering the Mullvad App #  Searching through the docs, I found the WireGuard on a router article explaining how to get an IP to use with Mullvad via API:
curl https://api.mullvad.net/wg/ -d account=YOURMULLVADACCOUNTNUMBER --data-urlencode pubkey=YOURPUBLICKEY Next, let&rsquo;s look at how the app requests IPs. Fortunately it&rsquo;s open-source and available on GitHub, so the only reverse-engineering we&rsquo;re going to be doing is reading some code. It turns out that the app uses a different API to request IPs, found in the push_wg_key function: https://api.mullvad.net/app/v1/wireguard-keys.
Testing Both APIs #  For testing, we&rsquo;ll be using the official WireGuard client. Let&rsquo;s open the client, click Add empty tunnel..., and give it a name:
   The tunnel will initially look like this:
   Copy the public key and execute the following to request our Mullvad IPs:
curl https://api.mullvad.net/wg/ -d account=YOURMULLVADACCOUNTNUMBER --data-urlencode pubkey=YOURPUBLICKEY The response will return an IPv4 and IPv6 address. Add the following to the configuration file:
[Interface] PrivateKey = &lt;PRIVATE KEY&gt; Address = &lt;IPv4 ADRESS&gt; DNS = 9.9.9.9 [Peer] PublicKey = 9hIGjit4ApkNGuEWYBLpahxokEoP0cT9CMZ+ELEygzo= AllowedIPs = 0.0.0.0/0 Endpoint = 194.36.25.18:51820 We use the de24-wireguard Mullvad server as peer and Quad9 as DNS server.
Let&rsquo;s activate the tunnel and browse to Mullvad&rsquo;s connection check:
   As expected, the Quad9 DNS server is not leaking through because Mullvad hijacks our DNS requests and redirects them to their DNS servers.
Next, we use the API the app uses to request the Mullvad IPs. We expect to get a different IP for which DNS hijacking is disabled. Before we can do this, we need to revoke the WireGuard key on the Mullvad website because we already requested an IP for this public key:
   After revoking the key, we run the following command:
curl -sSL https://api.mullvad.net/app/v1/wireguard-keys -H &#34;Content-Type: application/json&#34; -H &#34;Authorization: Token YOURMULLVADACCOUNTNUMBER&#34; -d &#39;{&#34;pubkey&#34;:&#34;YOURPUBLICKEY&#34;}&#39; Next, we replace the IP in Address field of the WireGuard config with the new IP we received. Then we re-activate the tunnel and visit Mullvad&rsquo;s connection check:
   Hooray, the Quad9 DNS servers leak through, so Mullvad is not hijacking our DNS traffic for this tunnel!
`}).add({id:2,href:"/posts/use-the-trezor-hardware-wallet-anonymously-inside-a-virtualbox-whonix-vm-with-external-wallets-like-adalite-and-monero-gui/",title:"Use the Trezor Hardware Wallet Anonymously Inside a VirtualBox Whonix VM With External Wallets Like Adalite and Monero GUI",description:"In the past, I used an old laptop running Qubes OS for any cryptocurrency-related stuff, and it worked great. It&rsquo;s where I first learned about Whonix, a desktop operating system designed to protect your privacy online. Unfortunately, Qubes OS is a bit picky about the hardware it runs on. My old laptop only has four gigs of RAM, and I could barely run two instances of MyEtherWallet in two separate qubes without the system running out of memory.",content:`In the past, I used an old laptop running Qubes OS for any cryptocurrency-related stuff, and it worked great. It&rsquo;s where I first learned about Whonix, a desktop operating system designed to protect your privacy online. Unfortunately, Qubes OS is a bit picky about the hardware it runs on. My old laptop only has four gigs of RAM, and I could barely run two instances of MyEtherWallet in two separate qubes without the system running out of memory.
The Final Straw #  When initially configuring my Qubes OS environment for Monero, I decided to go with the setup described in a user guide from the official Monero website:
 With Qubes + Whonix you can have a Monero wallet that is without networking and running on a virtually isolated system from the Monero daemon which has all of its traffic forced over Tor.
 Out of the blue, after more than a year of using this setup, I couldn&rsquo;t start the daemon and the wallet GUI simultaneously anymore. I only had enough RAM to launch one, but not both, which made the setup unusable. So I had to buy new hardware.
Reducing The Complexity #  I would have loved to get a NitroPad X230, a Qubes OS-certified laptop to tinker around with Qubes OS some more. Also, the guys at Nitrokey are doing a great job in the open-source space and deserve any support they get. But I ultimately decided to reduce the complexity of my crypto setup and went with a hardware wallet instead \u2014 the Trezor Model T.
I&rsquo;ll guide you through my new &ldquo;Whonix on VirtualBox&rdquo; setup and the steps required to configure it.
Import the VirtualBox Whonix Appliance #  First, we download the VirtualBox appliance provided by Whonix and make sure to verify the binary. This requires different steps depending on the OS you are using.
Next, we import the appliance into VirtualBox by clicking File \u2192 Import Appliance&hellip;, creating two VMs \u2014 the gateway and the workstation. The gateway connects us to the Tor network. The workstation will only connect through that gateway, so both VMs must run if we want to connect to the outside world from within the workstation VM.
Make sure to read the Post-installation Security Advice from the official Whonix docs. We change the default user password and install the latest updates for the gateway at the very least. After, we repeat the same for the workstation VM.
At this point, we can optionally clone the workstation VM to have a clean Whonix image if we ever want to start over from scratch.
Install the Trezor Dependencies #  We can now connect the Trezor device to our computer. We then right-click on the workstation VM and select Settings&hellip;. Under USB, we check the Enable USB Controller and add the Trezor device. This way, it will be automatically attached to the workstation VM.
   Let&rsquo;s start the VM, open a terminal, and import the udev rule for Trezor to enable communication with the Trezor device via Linux kernel:
sudo curl https://data.trezor.io/udev/51-trezor.rules -o /etc/udev/rules.d/51-trezor.rules Next, we download the SatoshiLabs 2021 Signing Key:
wget https://trezor.io/security/satoshilabs-2021-signing-key.asc We verify the authenticity of the key by running:
gpg --with-fingerprint ./satoshilabs-2021-signing-key.asc The value of the fingerprint is EB48 3B26 B078 A4AA 1B6F 425E E21B 6950 A2EC B65C. If it&rsquo;s not, something is very wrong \u2014 do NOT continue! If everything looks good, we import the key:
gpg --import ./satoshilabs-2021-signing-key.asc Then we download the Trezor Suite and corresponding signature by running the following in the terminal (replace XX.XX.X with the latest version):
wget https://suite.trezor.io/web/static/desktop/Trezor-Suite-XX.XX.X-linux-x86_64.AppImage wget https://suite.trezor.io/web/static/desktop/Trezor-Suite-XX.XX.X-linux-x86_64.AppImage.asc We verify the binaries by running:
gpg --verify ./Trezor-Suite-XX.XX.X-linux-x86_64.AppImage.asc The output should contain:
Good signature from &#34;SatoshiLabs 2021 Signing Key&#34; Next, we make the binary executable:
chmod +x ./Trezor-Suite-XX.XX.X-linux-x86_64.AppImage To launch the Trezor suite and connect to our hardware wallet, we run:
./Trezor-Suite-XX.XX.X-linux-x86_64.AppImage At this point, we can shut down the VM and take a snapshot so we can roll back later if we need to. I like to clone this VM again for each cryptocurrency requiring an external wallet. It increases the security and maintainability of the setup.
Using the Monero GUI #  Besides giving the workstation VM a little more RAM, Monero doesn&rsquo;t require additional setup since Whonix includes the Monero GUI. We launch the app and wait for the Monero daemon to sync, which might take a long time using Tor. After that, we&rsquo;re ready to go!
Setting Up Adalite #  Adalite is an open-source, in-browser wallet, and only a few steps are required to get it working.
First, we open the Tor browser and allow pop-up windows from https://adalite.io by adding an exception for it under Settings \u2192 Preferences \u2192 Privacy &amp; Security.
Next, we launch the Trezor Suite by running ./Trezor-Suite-XX.XX.X-linux-x86_64.AppImage. It starts the included Trezor Bridge, which Adalite requires to communicate with the Trezor device. We can verify the Trezor Bridge is running by navigating to http://127.0.0.1:21325/status/ in the browser.
The final step is to change two advanced settings of the Tor browser by navigating to about:config and clicking Accept the Risk and Continue. We set the network.proxy.no_proxies_on to 127.0.0.1:21325, so traffic to the Trezor Bridge is not proxied through the Tor network. We also need to disable First-Party Isolation by setting privacy.firstparty.isolate to false.
We can now use Adalite by navigating to https://adalite.io. It might be a good idea to bookmark that address, so you don&rsquo;t fall victim to a phishing attack in case of a typo.
Closing Thoughts #  For my purposes, this setup provides more than enough anonymity. Depending on your needs, it might be overkill or might not be anonymous or secure enough. It always depends on your threat model.
I don&rsquo;t like that SatoshLabs publishes a new signing key every year. Just one more thing to keep in mind come next year.
`}).add({id:3,href:"/posts/create-a-modern-css-only-fold-out-burger-menu/",title:"Create a Modern CSS-only Fold-Out Burger Menu",description:`For the last couple of months, I have been working on a custom Hugo theme in my free time. Most recently, I implemented a CSS-only burger fold-out menu to increase its responsiveness. I based the implementation on Erik Terwan&rsquo;s nifty pure CSS Hamburger fold-out menu which is pretty popular on CodePen. I modernized it by utilizing SVG and newer CSS selectors to make the code more declarative and scalable. It comes with the price of not supporting as many browsers, but honestly, who cares about Internet Explorer users?
`,content:`For the last couple of months, I have been working on a custom Hugo theme in my free time. Most recently, I implemented a CSS-only burger fold-out menu to increase its responsiveness. I based the implementation on Erik Terwan&rsquo;s nifty pure CSS Hamburger fold-out menu which is pretty popular on CodePen. I modernized it by utilizing SVG and newer CSS selectors to make the code more declarative and scalable. It comes with the price of not supporting as many browsers, but honestly, who cares about Internet Explorer users?
 .example { background: #3c3836; color: #ebdbb2; height: 200px; overflow: hidden; position: relative; width: 300px; }  What the Result Looks Like #  Have a look at the result (it&rsquo;s interactive):
 #example-result .menu-burger  * { position: absolute; } #example-result .menu-burger input { height: 32px; margin: 0; opacity: 0; width: 32px; z-index: 3; } #example-result .menu-burger svg { height: 32px; width: 32px; z-index: 2; } #example-result ul.menu-burger__item-list { background: #ebdbb2; bottom: 0; color: #3c3836; list-style: none; margin: 0; padding: 32px; top: 0; transform: translate(-100%, 0); transition: transform 0.5s cubic-bezier(0.9, 0, 0.1, 1); width: 200px; z-index: 1; } #example-result input:checked ~ .menu-burger__item-list { transform: none; } #example-result .menu-burger input:checked ~ svg line { stroke: #3c3836; } #example-result .menu-burger svg line:nth-of-type(1) { transform-origin: center 6px; } #example-result .menu-burger svg line:nth-of-type(2) { transform-origin: center 12px; } #example-result .menu-burger svg line:nth-of-type(3) { transform-origin: center 18px; } #example-result .menu-burger svg line { transition-duration: 0.5s; transition-property: stroke, opacity, transform; transition-timing-function: cubic-bezier(0.9, 0, 0.1, 1); } #example-result .menu-burger input:checked ~ svg line:nth-of-type(2) { opacity: 0; transform: scale(0.2); } #example-result .menu-burger input:checked ~ svg line:nth-of-type(1) { transform: translate(0, 6px) rotate(45deg); } #example-result .menu-burger input:checked ~ svg line:nth-of-type(3) { transform: translate(0, -6px) rotate(-45deg); }   Item 1 Item 2 Item 3    All of the illustrating examples use the following basic styling:
.example { background: #3c3836; color: #ebdbb2; height: 200px; overflow: hidden; position: relative; width: 300px; } Burger Anatomy #  As a starting point, I chose the menu-2 icon of the excellent, MIT-licensed Tabler Icon suite:
&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon icon-tabler icon-tabler-menu-2&#34; width=&#34;24&#34; height=&#34;24&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34;&gt; &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34;/&gt; &lt;line x1=&#34;4&#34; y1=&#34;6&#34; x2=&#34;20&#34; y2=&#34;6&#34; /&gt; &lt;line x1=&#34;4&#34; y1=&#34;12&#34; x2=&#34;20&#34; y2=&#34;12&#34; /&gt; &lt;line x1=&#34;4&#34; y1=&#34;18&#34; x2=&#34;20&#34; y2=&#34;18&#34; /&gt; &lt;/svg&gt; The icon looks like this:
 Here is a breakdown of the arrangement of the burger&rsquo;s three &lt;line /&gt; elements inside the SVG:
 When we later animate the lines, this will be important to know.
Menu Skeleton #  &lt;div class=&#34;menu-burger&#34;&gt; &lt;input type=&#34;checkbox&#34; /&gt; &lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon icon-tabler icon-tabler-menu-2&#34; viewBox=&#34;0 0 24 24&#34; stroke-width=&#34;2&#34; stroke=&#34;currentColor&#34; fill=&#34;none&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; &gt; &lt;path stroke=&#34;none&#34; d=&#34;M0 0h24v24H0z&#34; fill=&#34;none&#34; /&gt; &lt;line x1=&#34;4&#34; y1=&#34;6&#34; x2=&#34;20&#34; y2=&#34;6&#34; /&gt; &lt;line x1=&#34;4&#34; y1=&#34;12&#34; x2=&#34;20&#34; y2=&#34;12&#34; /&gt; &lt;line x1=&#34;4&#34; y1=&#34;18&#34; x2=&#34;20&#34; y2=&#34;18&#34; /&gt; &lt;/svg&gt; &lt;ul class=&#34;menu-burger__item-list&#34;&gt; &lt;li&gt;Item 1&lt;/li&gt; &lt;li&gt;Item 2&lt;/li&gt; &lt;li&gt;Item 3&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; The menu contains the burger and a list of menu items inside .menu-burger__item-list, which initially is not displayed. The &lt;input type=&quot;checkbox&quot; /&gt; is used as an invisible, &ldquo;CSS-only click handler&rdquo; indicating the menu state. Let&rsquo;s add some initial CSS next:
.menu-burger &gt; * { position: absolute; } .menu-burger input { height: 32px; margin: 0; opacity: 0; width: 32px; z-index: 3; } .menu-burger svg { height: 32px; width: 32px; z-index: 2; } ul.menu-burger__item-list { background: #ebdbb2; bottom: 0; color: #3c3836; list-style: none; margin: 0; padding: 32px; top: 0; transform: translate(-100%, 0); transition: transform 0.5s cubic-bezier(0.9, 0, 0.1, 1); width: 200px; z-index: 1; } input:checked ~ .menu-burger__item-list { transform: none; } .menu-burger input:checked ~ svg line { stroke: #3c3836; } The most important things going on here are:
 Any direct descendant of .menu-burger is positioned absolutely menu-burger__item-list, svg, and checkbox input are stacked on top of each other, ordered by z-index The dimensions of the input checkbox and svg exactly match To initially hide menu-burger__item-list, it&rsquo;s translated out of view A transition animation with a custom cubic-bezier easing-function is added to the transform property, so the fold-out of the menu looks nice. You can play with it on cubic-bezier.com. The &ldquo;click handler&rdquo; CSS magic is happening in input:checked ~ .menu-burger__item-list. ~ is the subsequent-sibling combinator. In this case it matches .menu-burger__item-list siblings of a :checked input checkbox and undoes the initial hiding transition. The same &ldquo;click handler&rdquo; logic is used to change the colors of the line elements from dark to light  The rest is self-explanatory, generic CSS styling. Here is what we have so far:
 #example-skeleton .menu-burger  * { position: absolute; } #example-skeleton .menu-burger input { height: 32px; margin: 0; opacity: 0; width: 32px; z-index: 3; } #example-skeleton .menu-burger svg { height: 32px; width: 32px; z-index: 2; } #example-skeleton ul.menu-burger__item-list { background: #ebdbb2; bottom: 0; color: #3c3836; list-style: none; margin: 0; padding: 32px; top: 0; transform: translate(-100%, 0); transition: transform 0.5s cubic-bezier(0.9, 0, 0.1, 1); width: 200px; z-index: 1; } #example-skeleton input:checked ~ .menu-burger__item-list { transform: none; } .menu-burger input:checked ~ svg line { stroke: #3c3836; }   Item 1 Item 2 Item 3    Now that we finished building the foundation, we can continue with the fun part!
Animate the Burger #  First, we style each &lt;line /&gt; by using declarative nth-of-type CSS selectors:
.collapsible__menu svg line:nth-of-type(1) { stroke: red; } .collapsible__menu svg line:nth-of-type(2) { stroke: green; } .collapsible__menu svg line:nth-of-type(3) { stroke: blue; } This styles the first, second and third line of svg like so:
 #example-rgb svg line:nth-of-type(1) { stroke: red; } #example-rgb svg line:nth-of-type(2) { stroke: green; } #example-rgb svg line:nth-of-type(3) { stroke: blue; }    Let&rsquo;s take a step back and think about what the animation should do:
 Fade out the middle line by scaling it down and changing its opacity to 0 Rotate the top and bottom lines to form an X. One way to do this is to vertically center both lines and rotate them by 45 degrees in opposing directions around their center.  Before we get started, we have to understand how transformation origins work in CSS:
 The transform origin is the point around which a transformation is applied. For example, the transform origin of the rotate() function is the center of rotation.
 In our case, the default transform-origin is (0,0). So before we apply transformations, we have to move the transform-origins of every line to their respective center:
 .menu-burger svg line:nth-of-type(1) { transform-origin: center 6px; } .menu-burger svg line:nth-of-type(2) { transform-origin: center 12px; } .menu-burger svg line:nth-of-type(3) { transform-origin: center 18px; } Next, use the cubic-bezier function again and apply it to every line property to be animated:
.menu-burger svg line { transition-duration: 0.5s; transition-property: stroke, opacity, transform; transition-timing-function: cubic-bezier(0.9, 0, 0.1, 1); } When clicked, we fade out the middle line of the burger:
.menu-burger input:checked ~ svg line:nth-of-type(2) { opacity: 0; transform: scale(0.2); } Finally, we vertically center and then rotate the top and bottom lines:
.menu-burger input:checked ~ svg line:nth-of-type(1) { transform: translate(0, 6px) rotate(45deg); } .menu-burger input:checked ~ svg line:nth-of-type(3) { transform: translate(0, -6px) rotate(-45deg); } Wrapping Up #  What do you think? Let me know in the comments or at me on Twitter.
I created a JSFiddle for you to play around with the code. Here is the entire CSS for reference:
.example { background: #3c3836; color: #ebdbb2; height: 200px; overflow: hidden; position: relative; width: 300px; } .menu-burger &gt; * { position: absolute; } .menu-burger input { height: 32px; margin: 0; opacity: 0; width: 32px; z-index: 3; } .menu-burger svg { height: 32px; width: 32px; z-index: 2; } ul.menu-burger__item-list { background: #ebdbb2; bottom: 0; color: #3c3836; list-style: none; margin: 0; padding: 32px; top: 0; transform: translate(-100%, 0); transition: transform 0.5s cubic-bezier(0.9, 0, 0.1, 1); width: 200px; z-index: 1; } input:checked ~ .menu-burger__item-list { transform: none; } .menu-burger input:checked ~ svg line { stroke: #3c3836; } .menu-burger svg line:nth-of-type(1) { transform-origin: center 6px; } .menu-burger svg line:nth-of-type(2) { transform-origin: center 12px; } .menu-burger svg line:nth-of-type(3) { transform-origin: center 18px; } .menu-burger svg line { transition-duration: 0.5s; transition-property: stroke, opacity, transform; transition-timing-function: cubic-bezier(0.9, 0, 0.1, 1); } .menu-burger input:checked ~ svg line:nth-of-type(2) { opacity: 0; transform: scale(0.2); } .menu-burger input:checked ~ svg line:nth-of-type(1) { transform: translate(0, 6px) rotate(45deg); } .menu-burger input:checked ~ svg line:nth-of-type(3) { transform: translate(0, -6px) rotate(-45deg); } `}).add({id:4,href:"/posts/use-sieve-filters-to-auto-sort-your-protonmail-inbox-into-subfolders/",title:"Use Sieve Filters to Auto-Sort Your ProtonMail Inbox into Subfolders",description:`Sieve is a programming language used for email filtering. Today, I show you how I automatically sort my ProtonMail inbox into folders and subfolders using custom sieve filters. My setup uses the catch-all feature requiring at least a ProtonMail Professional subscription and a properly configured custom domain.
`,content:`Sieve is a programming language used for email filtering. Today, I show you how I automatically sort my ProtonMail inbox into folders and subfolders using custom sieve filters. My setup uses the catch-all feature requiring at least a ProtonMail Professional subscription and a properly configured custom domain.
The ProtonMail Bridge has been supporting subfolders for a while now. With the release of the re-designed ProtonMail for web, subfolders are now officially supported. So now is a great time to share my setup with you guys!
The Goal #  I only want emails from unknown senders to land in my inbox, e.g., non-automated messages from people directly contacting me or emails from unknown websites. Sieve filters sort emails from well-known senders into folders and subfolders, like webshops or social media for which I have signed up.
I use root-level folders to categorize my email. Subfolders are for specific websites belonging to a category:
Inbox/ Webshops/ \u251C\u2500 Amazon/ \u251C\u2500 Ex Libris/ Entertainment/ \u251C\u2500 Netflix/ \u251C\u2500 Spotify/ Here, Webshops and Entertainment are the categories, and Amazon and Spotify are specific websites. For each website, I use a separate email address that maps to a pre-created folder. The generic structure of the email address I use to sign up for websites is the following:
category+website@schnerring.net For the example folder structure above, the email-to-folder mapping looks like this:
 webshops+amazon@schnerring.net \u2194 Webshops/Amazon/ webshops+exlibris@schnerring.net \u2194 Webshops/Ex Libris/ entertainment+netflix@schnerring.net \u2194 Entertainment/Netflix/ entertainment+spotify@schnerring.net \u2194 Entertainment/Spotify/ *@schnerring.net \u2194 Inbox/ (catch-all)  The Solution #  You can add custom sieve filters in the ProtonMail web client by navigating to Settings \u2192 Filters \u2192 Add sieve filter. The following snippet meets all of my requirements:
require [&quot;include&quot;, &quot;variables&quot;, &quot;fileinto&quot;, &quot;envelope&quot;]; if envelope :localpart :matches &quot;To&quot; &quot;*+*&quot; { set :lower &quot;category&quot; &quot;\${1}&quot;; set :lower &quot;website&quot; &quot;\${2}&quot;; } else { return; } if string :is &quot;\${website}&quot; &quot;exlibris&quot; { fileinto &quot;\${category}/Ex Libris&quot;; } else { fileinto &quot;\${category}&quot;; fileinto &quot;\${category}/\${website}&quot;; } The require command in the first line is used to load extensions that provide functionality, like fileinto to file messages into folders or variables to declare variables.
Next, the if-conditional checks the :localpart, the part before the @ symbol, of the To address. If it matches the pattern *+* (category+website):
 the value of the category variable is set to the match left of + symbol (\${1}) the value of the website variable is set to the match right of the + symbol (\${2}).  If :localpart does not match the pattern (else), the sieve filter exits (return).
Next, the actual sorting happens. Let&rsquo;s look into the else case first:
} else { fileinto &quot;\${category}&quot;; fileinto &quot;\${category}/\${website}&quot;; } Most of the magic happens here. The email is first moved to the category folder and then moved to the more specific website folder. This way, if the website subfolder does not (yet) exist, the email is at least moved into the root-level category folder. I find this useful when only ordering at a webshop once via guest checkout instead of signing up. This way, I don&rsquo;t need to bother creating an extra subfolder that will only ever contain one or two emails.
Lastly, let&rsquo;s cover the exception for the exlibris webshop in the if-part:
if string :is &quot;\${website}&quot; &quot;exlibris&quot; { fileinto &quot;\${category}/Ex Libris&quot;; } It is just a cosmetic exception. When I register at a webshop with webshops+exlibris@schnerring.net but want to map it to a folder called Ex Libris, an explicit mapping is required. Note that fileinto is not case-sensitive, so it is valid if the email address is webshops+amazon@schnerring.net, but the folder name is Webshops/Amazon/. It also is easily extensible by adding more elseif conditions.
For more details on advanced custom sieve filtering, check the official ProtonMail documentation.
`}).add({id:5,href:"/posts/set-up-azure-active-directory-domain-services-aadds-with-terraform/",title:"Set Up Azure Active Directory Domain Services (AADDS) with Terraform",description:`Update 2021-08-03 #  With v2.69.0 of the official Terraform azurerm provider released two weeks ago, the active_directory_domain_service and active_directory_domain_service_replica_set resources are now available. If you are newly adding AADDS, there is no point in reading any further \u2014 use the official resources.
I will switch in the coming weeks and write a short migration guide for the people using my AADDS Terraform module.
 Bringing traditional Active Directory Domain Services (AD DS) to the cloud, typically required to set up, secure, and maintain domain controllers (DCs). Azure Active Directory Domain Services (AADDS or Azure AD DS) is a Microsoft-managed solution, providing a subset of traditional AD DS features without the need to self-manage DCs.
One such service that requires AD DS features is Windows Virtual Desktop (WVD). I have successfully deployed WVD with Terraform, but until recently, I struggled to do the same with AADDS. Today, I show you how to deploy AADDS with Terraform.
`,content:`Update 2021-08-03 #  With v2.69.0 of the official Terraform azurerm provider released two weeks ago, the active_directory_domain_service and active_directory_domain_service_replica_set resources are now available. If you are newly adding AADDS, there is no point in reading any further \u2014 use the official resources.
I will switch in the coming weeks and write a short migration guide for the people using my AADDS Terraform module.
 Bringing traditional Active Directory Domain Services (AD DS) to the cloud, typically required to set up, secure, and maintain domain controllers (DCs). Azure Active Directory Domain Services (AADDS or Azure AD DS) is a Microsoft-managed solution, providing a subset of traditional AD DS features without the need to self-manage DCs.
One such service that requires AD DS features is Windows Virtual Desktop (WVD). I have successfully deployed WVD with Terraform, but until recently, I struggled to do the same with AADDS. Today, I show you how to deploy AADDS with Terraform.
If you are lazy, you can skip to the end and use the custom Terraform module I published to the Terraform Registry.
Prerequisites #  Before getting started, we need the following things:
 Active Azure subscription Azure Active Directory (Azure AD or AAD) tenant Install Terraform  Building Blocks #  So how do we figure out what the required resources are to deploy AADDS? By reverse-engineering the AADDS configuration wizard in the Azure Portal! We launch it by adding a new managed domain after navigating to Azure AD Domain Services.
What we find is that the following resources are required:
 Resource group Virtual network and subnet AAD DC Administrators user group  Using default values for the remaining configuration options, we can download an Azure Resource Manager (ARM) template in the final review step of the wizard.
Analyzing the ARM template reveals that besides the resource group, virtual network, and subnet, a Network Security Group (NSG) with the security rules required for AADDS is added.
The ARM template also contains the Microsoft.AAD/domainServices resource, with its parameters set to the configuration options from the wizard. The following is version 2021-03-01 of the ARM template format from the official Azure Template documentation:
{ &#34;name&#34;: &#34;string&#34;, &#34;type&#34;: &#34;Microsoft.AAD/domainServices&#34;, &#34;apiVersion&#34;: &#34;2021-03-01&#34;, &#34;location&#34;: &#34;string&#34;, &#34;tags&#34;: {}, &#34;properties&#34;: { &#34;domainName&#34;: &#34;string&#34;, &#34;replicaSets&#34;: [ { &#34;location&#34;: &#34;string&#34;, &#34;subnetId&#34;: &#34;string&#34; } ], &#34;ldapsSettings&#34;: { &#34;ldaps&#34;: &#34;string&#34;, &#34;pfxCertificate&#34;: &#34;string&#34;, &#34;pfxCertificatePassword&#34;: &#34;string&#34;, &#34;externalAccess&#34;: &#34;string&#34; }, &#34;resourceForestSettings&#34;: { &#34;settings&#34;: [ { &#34;trustedDomainFqdn&#34;: &#34;string&#34;, &#34;trustDirection&#34;: &#34;string&#34;, &#34;friendlyName&#34;: &#34;string&#34;, &#34;remoteDnsIps&#34;: &#34;string&#34;, &#34;trustPassword&#34;: &#34;string&#34; } ], &#34;resourceForest&#34;: &#34;string&#34; }, &#34;domainSecuritySettings&#34;: { &#34;ntlmV1&#34;: &#34;string&#34;, &#34;tlsV1&#34;: &#34;string&#34;, &#34;syncNtlmPasswords&#34;: &#34;string&#34;, &#34;syncKerberosPasswords&#34;: &#34;string&#34;, &#34;syncOnPremPasswords&#34;: &#34;string&#34;, &#34;kerberosRc4Encryption&#34;: &#34;string&#34;, &#34;kerberosArmoring&#34;: &#34;string&#34; }, &#34;domainConfigurationType&#34;: &#34;string&#34;, &#34;sku&#34;: &#34;string&#34;, &#34;filteredSync&#34;: &#34;string&#34;, &#34;notificationSettings&#34;: { &#34;notifyGlobalAdmins&#34;: &#34;string&#34;, &#34;notifyDcAdmins&#34;: &#34;string&#34;, &#34;additionalRecipients&#34;: [&#34;string&#34;] } } } The docs also reference the Azure Resource Manager QuickStart Template on GitHub. Its README confirms our previous findings but shows that the configuration wizard also must perform the following steps under the hood:
 Register the Azure Active Directory Application Service Principal 2565bd9d-da50-47d4-8b85-4c97f669dc36 Register the Microsoft.AAD Resource Provider  With everything figured out, we can continue with the fun part: Terraform!
Putting Everything Together #  Let&rsquo;s register the service principal and resource provider first:
resource &#34;azuread_service_principal&#34; &#34;aadds&#34; { application_id = &#34;2565bd9d-da50-47d4-8b85-4c97f669dc36&#34; } resource &#34;azurerm_resource_provider_registration&#34; &#34;aadds&#34; { name = &#34;Microsoft.AAD&#34; } Next, we add the AAD DC Administrators user group:
resource &#34;azuread_group&#34; &#34;aadds&#34; { display_name = &#34;AAD DC Administrators&#34; description = &#34;Delegated group to administer Azure AD Domain Services&#34; } Adding the resource group, virtual network, subnet, and NSG is pretty straightforward:
resource &#34;azurerm_resource_group&#34; &#34;aadds&#34; { name = &#34;aadds-rg&#34; location = &#34;Switzerland North&#34; } resource &#34;azurerm_virtual_network&#34; &#34;aadds&#34; { name = &#34;aadds-vnet&#34; resource_group_name = azurerm_resource_group.aadds.name location = &#34;Switzerland North&#34; address_space = [&#34;10.0.0.0/16&#34;]# AADDS DCs  dns_servers = [&#34;10.0.0.4&#34;, &#34;10.0.0.5&#34;] } resource &#34;azurerm_subnet&#34; &#34;aadds&#34; { name = &#34;aadds-snet&#34; resource_group_name = azurerm_resource_group.aadds.name virtual_network_name = azurerm_virtual_network.aadds.name address_prefixes = [&#34;10.0.0.0/24&#34;] } resource &#34;azurerm_network_security_group&#34; &#34;aadds&#34; { name = &#34;aadds-nsg&#34; location = &#34;Switzerland North&#34; resource_group_name = azurerm_resource_group.aadds.name security_rule { name = &#34;AllowRD&#34; access = &#34;Allow&#34; priority = 201 direction = &#34;Inbound&#34; protocol = &#34;Tcp&#34; source_address_prefix = &#34;CorpNetSaw&#34; source_port_range = &#34;*&#34; destination_address_prefix = &#34;*&#34; destination_port_range = &#34;3389&#34; } security_rule { name = &#34;AllowPSRemoting&#34; access = &#34;Allow&#34; priority = 301 direction = &#34;Inbound&#34; protocol = &#34;Tcp&#34; source_address_prefix = &#34;AzureActiveDirectoryDomainServices&#34; source_port_range = &#34;*&#34; destination_address_prefix = &#34;*&#34; destination_port_range = &#34;5986&#34; } } resource &#34;azurerm_subnet_network_security_group_association&#34; &#34;aadds&#34; { subnet_id = azurerm_subnet.aadds.id network_security_group_id = azurerm_network_security_group.aadds.id } Make sure to set dns_servers to the IP addresses of the DCs. You can find them on the Overview page of the managed domain after the deployment succeeded.
The final step is to add the AADDS deployment. Define the ARM template as Terraform templatefile named aadds-arm-template.tpl.json:
{ &#34;$schema&#34;: &#34;https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#&#34;, &#34;contentVersion&#34;: &#34;1.0.0.0&#34;, &#34;resources&#34;: [ { &#34;name&#34;: &#34;\${domainName}&#34;, &#34;type&#34;: &#34;Microsoft.AAD/domainServices&#34;, &#34;apiVersion&#34;: &#34;2021-03-01&#34;, &#34;location&#34;: &#34;\${location}&#34;, &#34;tags&#34;: \${tags}, &#34;properties&#34;: { &#34;domainName&#34;: &#34;\${domainName}&#34;, &#34;replicaSets&#34;: [ { &#34;location&#34;: &#34;\${location}&#34;, &#34;subnetId&#34;: &#34;\${subnetId}&#34; } ], &#34;domainSecuritySettings&#34;: { &#34;ntlmV1&#34;: &#34;\${ntlmV1}&#34;, &#34;tlsV1&#34;: &#34;\${tlsV1}&#34;, &#34;syncNtlmPasswords&#34;: &#34;\${syncNtlmPasswords}&#34;, &#34;syncKerberosPasswords&#34;: &#34;\${syncKerberosPasswords}&#34;, &#34;syncOnPremPasswords&#34;: &#34;\${syncOnPremPasswords}&#34;, &#34;kerberosRc4Encryption&#34;: &#34;\${kerberosRc4Encryption}&#34;, &#34;kerberosArmoring&#34;: &#34;\${kerberosArmoring}&#34; }, &#34;domainConfigurationType&#34;: &#34;\${domainConfigurationType}&#34;, &#34;sku&#34;: &#34;\${sku}&#34;, &#34;filteredSync&#34;: &#34;\${filteredSync}&#34;, &#34;notificationSettings&#34;: { &#34;notifyGlobalAdmins&#34;: &#34;\${notifyGlobalAdmins}&#34;, &#34;notifyDcAdmins&#34;: &#34;\${notifyDcAdmins}&#34;, &#34;additionalRecipients&#34;: \${additionalRecipients} } } } ] } We then populate its values dynamically like so:
resource &#34;azurerm_resource_group_template_deployment&#34; &#34;aadds&#34; { name = &#34;aadds-deploy&#34; resource_group_name = azurerm_resource_group.aadds.name deployment_mode = &#34;Incremental&#34; template_content = templatefile( &#34;\${path.module}/aadds-arm-template.tpl.json&#34;, {# Basics  &#34;domainName&#34; = &#34;aadds.schnerring.net&#34; &#34;location&#34; = &#34;Switzerland North&#34; &#34;sku&#34; = &#34;Standard&#34; &#34;domainConfigurationType&#34; = &#34;FullySynced&#34;# Networking  &#34;subnetId&#34; = azurerm_subnet.aadds.id# Administration  &#34;notifyGlobalAdmins&#34; = &#34;Enabled&#34; &#34;notifyDcAdmins&#34; = &#34;Enabled&#34; &#34;additionalRecipients&#34; = jsonencode([])# Synchronization  &#34;filteredSync&#34; = &#34;Enabled&#34;# Security  &#34;tlsV1&#34; = &#34;Enabled&#34; &#34;ntlmV1&#34; = &#34;Enabled&#34; &#34;syncNtlmPasswords&#34; = &#34;Enabled&#34; &#34;syncOnPremPasswords&#34; = &#34;Enabled&#34; &#34;kerberosRc4Encryption&#34; = &#34;Enabled&#34; &#34;syncKerberosPasswords&#34; = &#34;Enabled&#34; &#34;kerberosArmoring&#34; = &#34;Disabled&#34;# Tags  &#34;tags&#34; = jsonencode({}) } ) depends_on = [azurerm_resource_provider_registration.aadds] } Run terraform apply to deploy everything. It takes around 45 minutes to complete.
Wrapping Up #  I created a custom module wrapping the above functionality and published it to the Terraform Registry. You can also find the code on my GitHub along with some examples. I decided that the creation of network resources is out of the module&rsquo;s scope. Depending on what network topology you prefer, pre-provisioning the virtual network and subnet gives you more flexibility.
The module provides the same options as the Azure Portal configuration wizard. More advanced configuration options like LDAP and forests are not yet supported. Feel free to comment below, or open an issue or pull request on GitHub if you find something to improve.
A minimal deployment with the custom module looks like this:
resource &#34;azurerm_resource_group&#34; &#34;aadds&#34; { name = &#34;aadds-rg&#34; location = &#34;Switzerland North&#34; } resource &#34;azurerm_virtual_network&#34; &#34;aadds&#34; { name = &#34;aadds-vnet&#34; resource_group_name = azurerm_resource_group.aadds.name location = &#34;Switzerland North&#34; address_space = [&#34;10.0.0.0/16&#34;]# AADDS DCs  dns_servers = [&#34;10.0.0.4&#34;, &#34;10.0.0.5&#34;] } resource &#34;azurerm_subnet&#34; &#34;aadds&#34; { name = &#34;aadds-snet&#34; resource_group_name = azurerm_resource_group.aadds.name virtual_network_name = azurerm_virtual_network.aadds.name address_prefixes = [&#34;10.0.0.0/24&#34;] } module &#34;aadds&#34; { source = &#34;schnerring/aadds/azurerm&#34; version = &#34;0.1.1&#34; resource_group_name = azurerm_resource_group.aadds.name location = &#34;Switzerland North&#34; domain_name = &#34;aadds.schnerring.net&#34; subnet_id = azurerm_subnet.aadds.id } `}).add({id:6,href:"/posts/deploy-a-matrix-homeserver-to-azure-kubernetes-service-aks-with-terraform/",title:"Deploy a Matrix Homeserver to Azure Kubernetes Service (AKS) with Terraform",description:`Did you ever think about running a Matrix homeserver? In this post, we will set one up on the Azure Kubernetes Service (AKS). We will use the reference homeserver implementation, which is Synapse from the folks at matrix.org. This post focuses on the Kubernetes stuff, keeping Synapse configuration to a minimum. Things like federation, delegation and PostgreSQL are out of scope, because plenty of excellent guides and the official documentation exist covering that. The icing on the cake will be the Synapse Admin UI deployment with secure access to the administration endpoints to make management of our homeserver easier.
`,content:`Did you ever think about running a Matrix homeserver? In this post, we will set one up on the Azure Kubernetes Service (AKS). We will use the reference homeserver implementation, which is Synapse from the folks at matrix.org. This post focuses on the Kubernetes stuff, keeping Synapse configuration to a minimum. Things like federation, delegation and PostgreSQL are out of scope, because plenty of excellent guides and the official documentation exist covering that. The icing on the cake will be the Synapse Admin UI deployment with secure access to the administration endpoints to make management of our homeserver easier.
Preface #  Besides some basic knowledge about AKS, Kubernetes, and Terraform, we have to set up a couple of other things before getting started.
We need an AKS cluster with a configured Ingress Controller to be able to expose our homeserver to the world. I use Traefik 2 in combination with its Kubernetes Ingress implementation.
Synapse requires valid TLS certificates to work and ships with functionality to automatically provision Let&rsquo;s Encrypt certificates. However, I use cert-manager as a certificate management solution for all my services. So we skip over that part of the configuration, too.
The last thing we have to set up is Terraform with a properly configured kubernetes provider. If you do not want to use Terraform, transforming the code to regular YAML manifests is trivial.
Depending on your needs, reverse proxy (ingress) functionality and certificate management is the part where your setup differs the most. If you are starting out from scratch, check out my previous post, covering much of the steps required to set up the AKS cluster.
Ingress #  We work from the outside to the inside. The Ingress is what exposes our Kubernetes Service to the public internet. We also add a Namespace for all our Matrix resources to a new Terraform file matrix.tf:
resource &#34;kubernetes_namespace&#34; &#34;matrix&#34; { metadata { name = &#34;matrix&#34; } } resource &#34;kubernetes_ingress&#34; &#34;matrix&#34; { metadata { name = &#34;matrix-ing&#34; namespace = kubernetes_namespace.matrix.metadata.0.name annotations = { &#34;cert-manager.io/cluster-issuer&#34; = &#34;letsencrypt-staging&#34; &#34;traefik.ingress.kubernetes.io/router.tls&#34; = &#34;true&#34; } } spec { rule { host = var.synapse_server_name http { path { path = &#34;/_matrix&#34; backend { service_name = &#34;matrix-svc&#34; service_port = 8008 } } path { path = &#34;/_synapse/client&#34; backend { service_name = &#34;matrix-svc&#34; service_port = 8008 } } path { path = &#34;/&#34; backend { service_name = &#34;matrix-admin-svc&#34; service_port = 8080 } } } } tls { secret_name = &#34;matrix-tls-secret&#34; hosts = [var.synapse_server_name] } } } To route external traffic to the Synapse Service (matrix-svc), we set up the /_matrix and /_synapse/client endpoints according to the official reverse proxy documentation. The / endpoint routes traffic to the Synapse Admin UI (matrix-admin-svc). We do NOT expose the /_synapse/admin endpoint. We will look at how to access this endpoint at the end of this post.
After we finish testing, we must change the certificate issuer from letsencrypt-staging to letsencrypt-production. Later on, we will also define the var.synapse_server_name Terraform input variable.
Services #  Services expose our Synapse and Synapse Admin UI deployments as network services inside our Kubernetes cluster:
resource &#34;kubernetes_service&#34; &#34;matrix&#34; { metadata { name = &#34;matrix-svc&#34; namespace = kubernetes_namespace.matrix.metadata.0.name } spec { selector = { &#34;app&#34; = &#34;matrix&#34; } port { port = 8008 target_port = 8008 } } } resource &#34;kubernetes_service&#34; &#34;matrix_admin&#34; { metadata { name = &#34;matrix-admin-svc&#34; namespace = kubernetes_namespace.matrix.metadata.0.name } spec { selector = { &#34;app&#34; = &#34;matrix-admin&#34; } port { port = 8080 target_port = 80 } } } Pretty self-explanatory. We map the service ports to container ports of the deployments that we add in a later step.
Configuration Files #  Before adding the deployment to our cluster, we generate the initial configuration files for Synapse:
 homeserver.yaml: Synapse configuration matrix.schnerring.net.log.config: logging configuration matrix.schnerring.net.signature.key: the key, Synapse signs messages with  We can do that with the generate command which is part of Synapse:
kubectl run matrix-generate-pod \\  --stdin \\  --rm \\  --restart=Never \\  --command=true \\  --image matrixdotorg/synapse:latest \\  --env=&#34;SYNAPSE_REPORT_STATS=yes&#34; \\  --env=&#34;SYNAPSE_SERVER_NAME=matrix.schnerring.net&#34; \\  -- bash -c &#34;/start.py generate &amp;&amp; sleep 300&#34; This command creates a pod, runs generate, sleeps for 300 seconds, and then cleans itself up. Five minutes should be enough time to copy the generated files from the container before it terminates. The following command copies the entire /data directory from the container to a local synapse-config directory:
kubectl cp matrix-generate-pod:/data synapse-config We then store the three configuration files as Secret on the cluster. But before, make sure to change the value of handlers.file.filename from /homeserver.log to /data/homeserver.log inside the *.log.config file. Otherwise, you will run into a permission issue caused by the default logger configuration that I discovered.
locals { synapse_log_config = &#34;/data/\${var.synapse_server_name}.log.config&#34; synapse_signing_key_path = &#34;/data/\${var.synapse_server_name}.signing.key&#34; } resource &#34;kubernetes_secret&#34; &#34;matrix&#34; { metadata { name = &#34;matrix-secret&#34; namespace = kubernetes_namespace.matrix.metadata.0.name }# See also: https://github.com/matrix-org/synapse/blob/master/docker/README.md#generating-a-configuration-file  data = { &#34;homeserver.yaml&#34; = templatefile( &#34;\${path.module}/synapse-config/homeserver.tpl.yaml&#34;, { &#34;server_name&#34; = var.synapse_server_name &#34;report_stats&#34; = var.synapse_report_stats &#34;log_config&#34; = local.synapse_log_config &#34;signing_key_path&#34; = local.synapse_signing_key_path &#34;registration_shared_secret&#34; = var.synapse_registration_shared_secret &#34;macaroon_secret_key&#34; = var.synapse_macaroon_secret_key &#34;form_secret&#34; = var.synapse_form_secret } ) &#34;log.config&#34; = templatefile( &#34;\${path.module}/synapse-config/log.tpl.config&#34;, { &#34;log_filename&#34; = &#34;/data/homeserver.log&#34; &#34;log_level&#34; = &#34;INFO&#34; } ) &#34;signing.key&#34; = var.synapse_signing_key } } To protect the signing key and the secrets contained inside the homeserver.yaml file, we use the Terraform templatefile() function, which allows us to put variable placeholders into the configuration files that are interpolated during terraform apply. This way, we can commit the configuration files to source control securely. To denote the files as template files, we change the file names to homeserver.tpl.yaml and log.tpl.config. Here is an example of how to define interpolation sequences inside homeserver.yaml:
server_name: &#34;\${server_name}&#34; # ... # a secret which is used to sign access tokens. If none is specified, # the registration_shared_secret is used, if one is given; otherwise, # a secret key is derived from the signing key. # macaroon_secret_key: &#34;\${macaroon_secret_key}&#34; # a secret which is used to calculate HMACs for form values, to stop # falsification of values. Must be specified for the User Consent # forms to work. # form_secret: &#34;\${form_secret}&#34; Of course, you can also check out the config file templates on my GitHub.
To find the values inside the huge homeserver.yaml file, we use the following regular expression. It matches any line that is not a comment or whitespace:
^(?!^\\s*#)^(?!\\n).* All we have to do now is define the Terraform input variables and set them to the values we originally generated:
variable &#34;synapse_image_version&#34; { type = string description = &#34;Synapse image version.&#34; default = &#34;v1.33.2&#34; } variable &#34;synapse_server_name&#34; { type = string description = &#34;Public Synapse hostname.&#34; } variable &#34;synapse_report_stats&#34; { type = bool description = &#34;Enable anonymous statistics reporting.&#34; } variable &#34;synapse_signing_key&#34; { type = string description = &#34;Signing key Synapse signs messages with.&#34; sensitive = true } variable &#34;synapse_registration_shared_secret&#34; { type = string description = &#34;Allows registration of standard or admin accounts by anyone who has the shared secret.&#34; sensitive = true } variable &#34;synapse_macaroon_secret_key&#34; { type = string description = &#34;Secret which is used to sign access tokens.&#34; sensitive = true } variable &#34;synapse_form_secret&#34; { type = string description = &#34;Secret which is used to calculate HMACs for form values.&#34; sensitive = true } Persistent Volume Claim #  To be able to persist media, we create a PersistentVolumeClaim (PVC):
resource &#34;kubernetes_persistent_volume_claim&#34; &#34;matrix&#34; { metadata { name = &#34;matrix-pvc&#34; namespace = kubernetes_namespace.matrix.metadata.0.name } spec { access_modes = [&#34;ReadWriteOnce&#34;] resources { requests = { &#34;storage&#34; = &#34;4Gi&#34; } } } } Note that the default AKS StorageClass has the ReclaimPolicy set to Delete . I recommend defining a custom storage class for production. Setting its reclaim policy to Retain makes accidentally purging the media PVC much harder.
Synapse #  Let us finally deploy Synapse. We just need to mount the configuration files and the PVC we just defined:
resource &#34;kubernetes_deployment&#34; &#34;matrix&#34; { metadata { name = &#34;matrix-deploy&#34; namespace = kubernetes_namespace.matrix.metadata.0.name labels = { &#34;app&#34; = &#34;matrix&#34; } } spec { replicas = 1 selector { match_labels = { &#34;app&#34; = &#34;matrix&#34; } } strategy { type = &#34;Recreate&#34; } template { metadata { labels = { &#34;app&#34; = &#34;matrix&#34; } } spec { hostname = &#34;matrix&#34; restart_policy = &#34;Always&#34; security_context { run_as_user = &#34;991&#34; run_as_group = &#34;991&#34; fs_group = &#34;991&#34; run_as_non_root = true } container { name = &#34;synapse&#34; image = &#34;matrixdotorg/synapse:\${var.synapse_image_version}&#34; security_context { read_only_root_filesystem = true } port { container_port = 8008 } volume_mount { mount_path = &#34;/data&#34; name = &#34;data-vol&#34; } volume_mount { name = &#34;secret-vol&#34; mount_path = &#34;/data/homeserver.yaml&#34; sub_path = &#34;homeserver.yaml&#34; read_only = true } volume_mount { name = &#34;secret-vol&#34; mount_path = local.synapse_log_config sub_path = &#34;log.config&#34; read_only = true } volume_mount { name = &#34;secret-vol&#34; mount_path = local.synapse_signing_key_path sub_path = &#34;signing.key&#34; read_only = true } } volume { name = &#34;data-vol&#34; persistent_volume_claim { claim_name = &#34;matrix-pvc&#34; } } volume { name = &#34;secret-vol&#34; secret { secret_name = &#34;matrix-secret&#34; } } } } } } It is good practice to lock down the container by making the root filesystem read-only, if possible. We also run the container as the 991 user and group, respectively, the default user used by Synapse.
To deploy everything, we run the following commands:
terraform plan -out infrastructure.tfplan terraform apply infrastructure.tfplan After the deployment succeeds, do not forget to change the cluster issuer to letsencrypt-production and terraform apply again.
Next, we register a new user. Synapse includes the register_new_matrix_user command. First, we query the name of the pod:
kubectl get pods --namespace matrix We then run the following to connect to the pod:
kubectl exec --stdin --tty --namespace matrix matrix-deploy-xxxxxxxxxx-xxxxx -- bash Now we register the user:
register_new_matrix_user \\  --admin \\  --user michael \\  --config /data/homeserver.yaml \\  http://localhost:8008 We use Element or any other Matrix client and sign in. Great!
Synapse Admin UI #  The Synapse API includes administration endpoints but lacks a UI for administration tasks. There is an open GitHub issue which seems to be inactive. However, awesometechnologies/synapse-admin is being actively developed and works well.
We already configured the ingress to route traffic to the matrix-admin-svc, so the only thing missing is the deployment:
resource &#34;kubernetes_deployment&#34; &#34;matrix_admin&#34; { metadata { name = &#34;matrix-admin-deploy&#34; namespace = kubernetes_namespace.matrix.metadata.0.name labels = { &#34;app&#34; = &#34;matrix-admin&#34; } } spec { replicas = 1 selector { match_labels = { &#34;app&#34; = &#34;matrix-admin&#34; } } strategy { type = &#34;Recreate&#34; } template { metadata { labels = { &#34;app&#34; = &#34;matrix-admin&#34; } } spec { hostname = &#34;matrix-admin&#34; restart_policy = &#34;Always&#34; container { name = &#34;synapse-admin&#34; image = &#34;awesometechnologies/synapse-admin:latest&#34; port { container_port = 80 } } } } } } No configuration is required because the Admin UI is a client-side application. After running terraform apply, we can browse to matrix.schnerring.net to access the app:
   Synapse Admin UI requires access to the _synapse/admin endpoint. But we do not want to expose that endpoint to the public internet, so we have to connect to it by other means. kubectl port-forward allows us to securely forward a local port to a port on a Kubernetes service:
kubectl port-forward service/matrix-svc --namespace matrix 8008:8008 We can now enter http://localhost:8008 as homeserver URL and login to the admin UI with the user we created earlier:
   What&rsquo;s Next? #  Regardless of what you plan on doing with your homeserver, replacing SQLite with PostgreSQL should be at the top of the priority list. Other than that, there is tons of other stuff to configure depending on your needs.
I am super happy with what we have built and curious about what you think. I would appreciate it if you shared your opinion in the comments below.
`}).add({id:7,href:"/posts/use-terraform-to-deploy-the-remark42-commenting-system-to-kubernetes-and-integrate-it-with-a-hugo-website/",title:"Use Terraform to Deploy the Remark42 Commenting System to Kubernetes and Integrate it with a Hugo Website",description:`Building upon our previous work, we will deploy Remark42 on Kubernetes with Terraform and integrate it with your existing Hugo website. Make sure to check out my previous posts about creating a Hugo Website and deploying an Azure Kubernetes Service cluster if you haven&rsquo;t already.
`,content:`Building upon our previous work, we will deploy Remark42 on Kubernetes with Terraform and integrate it with your existing Hugo website. Make sure to check out my previous posts about creating a Hugo Website and deploying an Azure Kubernetes Service cluster if you haven&rsquo;t already.
About Remark42 #   Remark42 is a self-hosted, lightweight, and simple (yet functional) commenting system, which doesn&rsquo;t spy on users.
 I like simplicity, I am a privacy enthusiast, and I build this blog with this in mind. More popular, hands-off solutions like Disqus offer easier integration and more sophisticated features, like automated spam moderation and advertising. But for my intents, it&rsquo;s too bloated and invasive. For low-traffic websites like mine, Remark42 is just the better fit.
Preparation #  Besides a Hugo website and a Kubernetes cluster, you will have to install the following software on your workstation:
 Terraform kompose (optional)  Converting the original docker-compose.yml #  The official Remark42 repository includes a docker-compose.yml that we can download:
curl -O https://raw.githubusercontent.com/umputun/remark42/master/docker-compose.yml We then run kompose convert to generate regular Kubernetes YAML manifests from the docker-compose.yml file:
Kubernetes file &#34;remark-deployment.yaml&#34; created Kubernetes file &#34;remark-claim0-persistentvolumeclaim.yaml&#34; created To figure out what resources we need to create, we use the generated manifests as a starting point.
Create a Namespace #  First, we create the Namespace where our Remark42 resources will reside. We add the following Terraform code to a new file named remark42.yml:
resource &#34;kubernetes_namespace&#34; &#34;remark42&#34; { metadata { name = &#34;remark42&#34; } } Deploy the changes by running:
terraform plan -out infrastructure.tfplan terraform apply infrastructure.tfplan Create the Persistent Volume Claim #  To enable persistence for Remark42, we create a PersistentVolumeClaim (PVC) resource. Using the generate remark-claim0-persistentvolumeclaim.yaml file as a blueprint, we can easily derive the Terraform equivalent from it and add it to the remark42.tf file:
resource &#34;kubernetes_persistent_volume_claim&#34; &#34;remark42&#34; { metadata { name = &#34;remark42-pvc&#34; namespace = kubernetes_namespace.remark42.metadata.0.name labels = { &#34;app&#34; = &#34;remark42-pvc&#34; } } spec { access_modes = [&#34;ReadWriteOnce&#34;] storage_class_name = &#34;azurefile&#34; resources { requests = { &#34;storage&#34; = &#34;1Gi&#34; } } } } AKS comes pre-configured with multiple StorageClasses. Here, I use the azurefile storage class to dynamically provision a persistent volume with Azure Files. At the time of this writing, I use a B2ms-sized VM as a node which is limited to four data disks. Using Azure Files whenever possible helps me circumventing this limitation.
Create ConfigMap and Secret #  To store configuration parameters for our Remark42 deployment, we make use of Kubernetes ConfigMap and Secret resources.
To store sensitive values, we use Secret:
resource &#34;kubernetes_secret&#34; &#34;remark42&#34; { metadata { name = &#34;remark42-secret&#34; namespace = kubernetes_namespace.remark42.metadata.0.name } data = { &#34;SECRET&#34; = random_password.remark42_secret.result } } For non-sensitive stuff, we use ConfigMap:
resource &#34;kubernetes_config_map&#34; &#34;remark42&#34; { metadata { name = &#34;remark42-cm&#34; namespace = kubernetes_namespace.remark42.metadata.0.name } data = { &#34;REMARK_URL&#34; = &#34;https://\${cloudflare_record.remark42.hostname}&#34; &#34;SITE&#34; = &#34;schnerring.net&#34; } } For this post, I have kept the configuration to a minimum:
 REMARK_URL: URL to Remark42 server SITE: site name(s) SECRET: secret key  Check the official documentation or my code on GitHub for more configuration options.
You might have noticed that I reference a cloudflare_record in the REMARK_URL part. That&rsquo;s because I also manage my DNS records with Terraform. The DNS record for remark42.schnerring.net pointing to the DNS record of my cluster looks like this:
resource &#34;cloudflare_record&#34; &#34;remark42&#34; { zone_id = cloudflare_zone.schnerring_net.id name = &#34;remark42&#34; type = &#34;CNAME&#34; value = cloudflare_record.traefik.hostname proxied = true } Create the Deployment #  Next, we add the Deployment to the remark42.tf file, using the remark-deployment.yaml file as a model. We map the previously defined configuration parameters to environment variables and mount the PVC to /srv/var.
resource &#34;kubernetes_deployment&#34; &#34;remark42&#34; { metadata { name = &#34;remark42-deploy&#34; namespace = kubernetes_namespace.remark42.metadata.0.name labels = { &#34;app&#34; = &#34;remark42&#34; } } spec { replicas = 1 selector { match_labels = { &#34;app&#34; = &#34;remark42&#34; } } strategy { type = &#34;Recreate&#34; } template { metadata { labels = { &#34;app&#34; = &#34;remark42&#34; } } spec { hostname = &#34;remark42&#34; restart_policy = &#34;Always&#34; container { name = &#34;remark42&#34; image = &#34;umputun/remark42:\${var.remark42_image_version}&#34; port { container_port = 8080 } env { name = &#34;REMARK_URL&#34; value_from { config_map_key_ref { key = &#34;REMARK_URL&#34; name = &#34;remark42-cm&#34; } } } env { name = &#34;SECRET&#34; value_from { secret_key_ref { key = &#34;SECRET&#34; name = &#34;remark42-secret&#34; } } } env { name = &#34;SITE&#34; value_from { config_map_key_ref { key = &#34;SITE&#34; name = &#34;remark42-cm&#34; } } } volume_mount { mount_path = &#34;/srv/var&#34; name = &#34;remark42-vol&#34; } } volume { name = &#34;remark42-vol&#34; persistent_volume_claim { claim_name = &#34;remark42-pvc&#34; } } } } } } Create the Service #  To expose our deployment as a network service, we create a Service resource by adding the following to the remark42.tf file:
resource &#34;kubernetes_service&#34; &#34;remark42&#34; { metadata { name = &#34;remark42-svc&#34; namespace = kubernetes_namespace.remark42.metadata.0.name } spec { selector = { &#34;app&#34; = &#34;remark42&#34; } port { name = &#34;http&#34; port = 80 target_port = 8080 } } } Create the Ingress #  I use Traefik 2 as Ingress Controller in combination with the Traefik Kubernetes Ingress provider. To manage Let&rsquo;s Encrypt certificates, I use cert-manager. So depending on your cluster configuration, the following steps might differ.
Let us add an Ingress to the remark42.tf file, to expose our service to the world:
resource &#34;kubernetes_ingress&#34; &#34;remark42&#34; { metadata { name = &#34;remark42-ing&#34; namespace = kubernetes_namespace.remark42.metadata.0.name annotations = { &#34;cert-manager.io/cluster-issuer&#34; = &#34;letsencrypt-production&#34; &#34;traefik.ingress.kubernetes.io/router.tls&#34; = &#34;true&#34; } } spec { rule { host = cloudflare_record.remark42.hostname http { path { path = &#34;/&#34; backend { service_name = &#34;remark42-svc&#34; service_port = 80 } } } } tls { hosts = [cloudflare_record.remark42.hostname] secret_name = &#34;remark42-tls-secret&#34; } } } Now run terraform apply to deploy everything. Note that we are using letsencrypt-staging as cluster issuer. We will have to change this to letsencrypt-production once we finished testing.
Browse to the demo site at https://remark42.schnerring.net/web and check whether Remark42 works. If you want to post a comment on the demo site, make sure to add the remark site ID to the SITE environment variable, separated by a , (i.e., schnerring.net,remark).
Integrate Remark42 with Hugo #  To add the Remark42 comment widget to our Hugo site, we have to integrate it with our theme. At the time of this writing, I use the Hello Friend theme, which includes a partial template for the comment section. We add the Remark42 widget to the layouts/partials/comments.html file:
&lt;div id=&#34;remark42&#34;&gt;&lt;/div&gt; &lt;script&gt; var remark_config = { host: &#34;https://remark42.schnerring.net&#34;, site_id: &#34;schnerring.net&#34;, theme: getHelloFriendTheme(), show_email_subscription: false, }; &lt;/script&gt; &lt;script&gt; !(function (e, n) { for (var o = 0; o &lt; e.length; o++) { var r = n.createElement(&#34;script&#34;), c = &#34;.js&#34;, d = n.head || n.body; &#34;noModule&#34; in r ? ((r.type = &#34;module&#34;), (c = &#34;.mjs&#34;)) : (r.async = !0), (r.defer = !0), (r.src = remark_config.host + &#34;/web/&#34; + e[o] + c), d.appendChild(r); } })(remark_config.components || [&#34;embed&#34;], document); &lt;/script&gt; You can find more configuration options for the widget in the Remark42 GitHub README.
Next, we implement the getHelloFriendTheme() function, so Remark42 loads the correct theme. The Hello Friend theme stores the current theme in the local storage of the browser. Knowing that, implementing the function is pretty straight forward:
&lt;script&gt; const defaultTheme = &#34;light&#34;; // same as defaultTheme in config.toml  function getHelloFriendTheme() { const theme = localStorage &amp;&amp; localStorage.getItem(&#34;theme&#34;); if (!theme) { return defaultTheme; } else { return theme; } } &lt;/script&gt; The last thing we have to take care of is to also toggle the Remark42 theme, when clicking the theme toggle button of the Hello Friend theme. To do so, we register an additional click event handler to the .theme-toggle button and call the window.REMARK42.changeTheme() function:
&lt;script&gt; const themeToggle = document.querySelector(&#34;.theme-toggle&#34;); themeToggle.addEventListener(&#34;click&#34;, () =&gt; { setTimeout(() =&gt; window.REMARK42.changeTheme(getHelloFriendTheme()), 10); }); &lt;/script&gt; Note that we wait 10 ms before reading from local storage to avoid race conditions. All we have to do now is to enable comments by setting comments: true via Hugo Front Matter.
What Do You Think? #  You can find all the code on my GitHub. I also tagged the commits to make it easier to find the code for future reference:
 schnerring/infrastructure (Terraform, tag v0.2.0) schnerring/schnerring.github.io (Hugo, tag v1.1.0)  Any feedback in the comments below is appreciated.
`}).add({id:8,href:"/posts/use-terraform-to-deploy-an-azure-kubernetes-service-aks-cluster-traefik-2-cert-manager-and-lets-encrypt-certificates/",title:"Use Terraform to Deploy an Azure Kubernetes Service (AKS) Cluster, Traefik 2, cert-manager, and Let's Encrypt Certificates",description:`In this post, we will deploy a simple Azure Kubernetes Service (AKS) cluster from scratch. To expose our web services securely, we will install Traefik 2 and configure cert-manager to manage Let&rsquo;s Encrypt certificates. The best part about it: we will do everything with Terraform.
`,content:`In this post, we will deploy a simple Azure Kubernetes Service (AKS) cluster from scratch. To expose our web services securely, we will install Traefik 2 and configure cert-manager to manage Let&rsquo;s Encrypt certificates. The best part about it: we will do everything with Terraform.
Prerequisites #  Keep in mind that I have tested the steps that follow on Windows. So if you are using another OS, you might have to modify them slightly. I also omit some non-essential steps in between, so it helps if you are already familiar with Azure, Kubernetes, and Terraform.
To follow along, you will need the following things:
 An active Azure subscription Install Terraform Install kubectl A registered domain A DNS provider:  that supports cert-manager DNS01 challenge validation with API access, so we can manage DNS records with Terraform \u2014 I use Cloudflare    Overview #  Here is an outline of the steps required to build our solution:
 Setup Terraform Create the AKS cluster Deploy cert-manager Configure Let&rsquo;s Encrypt certificates Deploy Traefik Deploy a demo application  Step 1: Setup Terraform #  We will make use of Terraform providers to put everything together:
 azurerm to manage our AKS cluster helm to deploy cert-manager and Traefik kubernetes to manage namespaces and deploy our demo app kubernetes-alpha to manage CRD resources cloudflare to manage DNS records  We add a provider.tf file with the following content:
terraform { required_version = &#34;= 0.14.9&#34; required_providers { azurerm = { source = &#34;azurerm&#34; version = &#34;=2.56.0&#34; } cloudflare = { source = &#34;cloudflare/cloudflare&#34; version = &#34;=2.20.0&#34; } helm = { source = &#34;helm&#34; version = &#34;=2.1.1&#34; } kubernetes = { source = &#34;kubernetes&#34; version = &#34;=2.1.0&#34; } kubernetes-alpha = { source = &#34;kubernetes-alpha&#34; version = &#34;=0.3.2&#34; } } } provider &#34;azurerm&#34; { features {} } provider &#34;cloudflare&#34; {} For now, we only configured the azurerm and cloudflare providers. After we set up the AKS cluster, we will configure the helm, kubernetes, and kubernetes-alpha providers.
I have opted to configure the azurerm provider with environment variables. You might want to choose a different approach depending on your needs.
To authenticate the cloudflare provider, I use a Cloudflare API Token with Edit Zone permissions.
After, we have to make sure to run terraform init to get started.
Step 2: Create the AKS cluster #  Creating a production-ready AKS cluster is out of scope for this post, which means that we will not delve too deep into AKS configuration. There are many things we are skipping over, like backups and monitoring. For a little more elaborate example, check out the official Terraform on Azure documentation.
We create a new file k8s.tf with the following content:
resource &#34;azurerm_resource_group&#34; &#34;k8s&#34; { name = &#34;k8s-rg&#34; location = var.location } resource &#34;random_id&#34; &#34;random&#34; { byte_length = 2 } resource &#34;azurerm_kubernetes_cluster&#34; &#34;k8s&#34; { name = &#34;k8s-aks&#34; resource_group_name = azurerm_resource_group.k8s.name location = var.location tags = var.tags dns_prefix = &#34;k8saks\${random_id.random.dec}&#34; default_node_pool { name = &#34;default&#34; node_count = 1 vm_size = &#34;Standard_B2s&#34; } identity { type = &#34;SystemAssigned&#34; } } Note that I have defined the var.location and var.tags variables in a separate variables.tf file.
To be able to access the AKS cluster locally with kubectl, we define a Terraform output in the outputs.tf file:
output &#34;kube_config&#34; { value = azurerm_kubernetes_cluster.k8s.kube_config_raw description = &#34;kubeconfig for kubectl access.&#34; sensitive = true } We have to set sensitive = true so our credentials will not get leaked, which could happen if we later decide to run Terraform with GitHub Actions. We apply our configuration by running Terraform:
terraform plan -out infrastructure.tfplan terraform apply infrastructure.tfplan After the deployment completes, we set up kubectl to be able to access our cluster:
terraform output -raw kube_config &gt; ~/.kube/config We check the deployment by running kubectl get all:
NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.0.0.1 &lt;none&gt; 443/TCP 3m54s Step 3: Deploy cert-manager #  To issue free Let&rsquo;s Encrypt certificates for the web services we provide, the first thing we have to deploy is cert-manager. We need to configure the helm provider first. While we are on it, we also configure the kubernetes and kubernetes-alpha providers:
provider &#34;helm&#34; { kubernetes { host = azurerm_kubernetes_cluster.k8s.kube_config.0.host client_certificate = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.client_certificate) client_key = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.client_key) cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.cluster_ca_certificate) } } provider &#34;kubernetes&#34; { host = azurerm_kubernetes_cluster.k8s.kube_config.0.host client_certificate = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.client_certificate) client_key = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.client_key) cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.cluster_ca_certificate) } provider &#34;kubernetes-alpha&#34; { host = azurerm_kubernetes_cluster.k8s.kube_config.0.host client_certificate = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.client_certificate) client_key = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.client_key) cluster_ca_certificate = base64decode(azurerm_kubernetes_cluster.k8s.kube_config.0.cluster_ca_certificate) } Stacking the providers above with our managed Kubernetes cluster resources can lead to errors and should be avoided. I will mention this once more at the end of the post.
Next, we deploy cert-manager with Helm by adding the following Terraform code to the k8s.tf file:
resource &#34;kubernetes_namespace&#34; &#34;cert_manager&#34; { metadata { name = &#34;cert-manager&#34; } } resource &#34;helm_release&#34; &#34;cert_manager&#34; { name = &#34;cert-manager&#34; repository = &#34;https://charts.jetstack.io&#34; chart = &#34;cert-manager&#34; version = &#34;1.3.1&#34; namespace = kubernetes_namespace.cert_manager.metadata[0].name set { name = &#34;installCRDs&#34; value = &#34;true&#34; } } We then run terraform apply to deploy cert-manager. We then check our work by running kubectl get all --namespace cert-manager, which should display something like this:
NAME READY STATUS RESTARTS AGE pod/cert-manager-7998c69865-vrvrd 1/1 Running 0 75s pod/cert-manager-cainjector-7b744d56fb-qb54k 1/1 Running 0 75s pod/cert-manager-webhook-7d6d4c78bc-svzq5 1/1 Running 0 75s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/cert-manager ClusterIP 10.0.141.59 &lt;none&gt; 9402/TCP 75s service/cert-manager-webhook ClusterIP 10.0.18.192 &lt;none&gt; 443/TCP 75s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/cert-manager 1/1 1 1 75s deployment.apps/cert-manager-cainjector 1/1 1 1 75s deployment.apps/cert-manager-webhook 1/1 1 1 75s NAME DESIRED CURRENT READY AGE replicaset.apps/cert-manager-7998c69865 1 1 1 75s replicaset.apps/cert-manager-cainjector-7b744d56fb 1 1 1 75s replicaset.apps/cert-manager-webhook-7d6d4c78bc 1 1 1 75s Step 4: Configure Let&rsquo;s Encrypt Certificates #  In Kubernetes, Issuers are Kubernetes resources representing certificate authorities able to generate certificates. We have to create a single ClusterIssuer, a cluster-wide Issuer, using DNS01 challenge validation with Let&rsquo;s Encrypt servers. As mentioned earlier, we will use Cloudflare, but many other DNS providers are supported.
First, we need to create a Cloudflare API Token on the Cloudflare website, at User Profile \u2192 API Tokens. The following permissions are required:
 Zone - DNS - Edit Zone - Zone - Read  To securely pass the token to Terraform, we create a sensitive variable. We also add a variable containing the email address where Let&rsquo;s Encrypt can notify us about expiring certificates:
variable &#34;letsencrypt_email&#34; { type = string description = &#34;Email address that Let&#39;s Encrypt will use to send notifications about expiring certificates and account-related issues to.&#34; sensitive = true } variable &#34;letsencrypt_cloudflare_api_token&#34; { type = string description = &#34;Cloudflare API token with Zone-DNS-Edit and Zone-Zone-Read permissions, which is required for DNS01 challenge validation.&#34; sensitive = true } With Terraform, we then add the secret containing the API token to our cluster. Since ClusterIssuer is a cluster-scoped resource, we need to make sure the secret is globally available by putting it in the cert-manager namespace:
resource &#34;kubernetes_secret&#34; &#34;letsencrypt_cloudflare_api_token_secret&#34; { metadata { name = &#34;letsencrypt-cloudflare-api-token-secret&#34; namespace = &#34;cert-manager&#34; } data = { &#34;api-token&#34; = var.letsencrypt_cloudflare_api_token } } Next, we add the staging and production ClusterIssuer cert-manager CRD resources that use Let&rsquo;s Encrypt servers. We will have to use regular Kubernetes YAML manifests since we cannot deploy CRDs with the kubernetes provider. Here, the kubernetes_manifest resource of the kubernetes-alpha provider comes in. Together with the Terraform yamldecode() and templatefile() functions, we get a pretty nice solution.
Let&rsquo;s start by defining the letsencrypt-issuer.tpl.yaml template file:
apiVersion: cert-manager.io/v1 kind: ClusterIssuer metadata: name: \${name} spec: acme: email: \${email} server: \${server} privateKeySecretRef: name: issuer-account-key-\${name} solvers: - dns01: cloudflare: apiTokenSecretRef: name: \${api_token_secret_name} key: \${api_token_secret_data_key} We then create the staging and production ClusterIssuers like so:
resource &#34;kubernetes_manifest&#34; &#34;letsencrypt_issuer_staging&#34; { provider = kubernetes-alpha manifest = yamldecode(templatefile( &#34;\${path.module}/letsencrypt-issuer.tpl.yaml&#34;, { &#34;name&#34; = &#34;letsencrypt-staging&#34; &#34;email&#34; = var.letsencrypt_email &#34;server&#34; = &#34;https://acme-staging-v02.api.letsencrypt.org/directory&#34; &#34;api_token_secret_name&#34; = kubernetes_secret.letsencrypt_cloudflare_api_token_secret.metadata[0].name &#34;api_token_secret_data_key&#34; = keys(kubernetes_secret.letsencrypt_cloudflare_api_token_secret.data)[0] } )) depends_on = [helm_release.cert_manager] } resource &#34;kubernetes_manifest&#34; &#34;letsencrypt_issuer_production&#34; { provider = kubernetes-alpha manifest = yamldecode(templatefile( &#34;\${path.module}/letsencrypt-issuer.tpl.yaml&#34;, { &#34;name&#34; = &#34;letsencrypt-production&#34; &#34;email&#34; = var.letsencrypt_email &#34;server&#34; = &#34;https://acme-v02.api.letsencrypt.org/directory&#34; &#34;api_token_secret_name&#34; = kubernetes_secret.letsencrypt_cloudflare_api_token_secret.metadata[0].name &#34;api_token_secret_data_key&#34; = keys(kubernetes_secret.letsencrypt_cloudflare_api_token_secret.data)[0] } )) depends_on = [helm_release.cert_manager] } Now we terraform apply the changes.
Step 5: Deploy Traefik #  To manage external access to our Kubernetes cluster, we need to configure Kubernetes Ingress resources. To satisfy an Ingress, we first need to configure an Ingress Controller. We will use Traefik for this.
To manage ingress, we could also use the Traefik IngressRoute CRD. At the time of this writing, cert-manager cannot directly interface with Traefik CRDs, so we would have to manage Certificate and Secret resources manually, which is cumbersome.
We add the following to the k8s.tf file:
resource &#34;kubernetes_namespace&#34; &#34;traefik&#34; { metadata { name = &#34;traefik&#34; } } resource &#34;helm_release&#34; &#34;traefik&#34; { name = &#34;traefik&#34; repository = &#34;https://helm.traefik.io/traefik&#34; chart = &#34;traefik&#34; version = &#34;9.18.2&#34; namespace = kubernetes_namespace.traefik.metadata[0].name set { name = &#34;ports.web.redirectTo&#34; value = &#34;websecure&#34; }# Trust private AKS IP range  set { name = &#34;additionalArguments&#34; value = &#34;{--entryPoints.websecure.forwardedHeaders.trustedIPs=10.0.0.0/8}&#34; } } Setting ports.web.redirectTo to websecure forces all HTTP traffic to be redirected to HTTPS.
To configure Traefik to trust forwarded headers from Azure, we set entryPoints.websecure.forwardedHeaders.trustedIPs=10.0.0.0/8.
After running terraform apply, we check the deployment by running kubectl get all --namespace traefik:
NAME READY STATUS RESTARTS AGE pod/traefik-6b6767d778-hxzzw 1/1 Running 0 68s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/traefik LoadBalancer 10.0.247.4 51.103.157.225 80:32468/TCP,443:31284/TCP 69s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/traefik 1/1 1 1 69s NAME DESIRED CURRENT READY AGE replicaset.apps/traefik-6b6767d778 1 1 1 69s Next, we add a DNS record with the IP of our Traefik service. To obtain the external IP address of the service, we leverage the kubernetes_service Data Source of the kubernetes provider. We then add the DNS record k8s.schnerring.net pointing to the external IP of Traefik.
Let us update the k8s.tf file accordingly and terraform apply the changes:
data &#34;kubernetes_service&#34; &#34;traefik&#34; { metadata { name = helm_release.traefik.name namespace = helm_release.traefik.namespace } } resource &#34;cloudflare_record&#34; &#34;traefik&#34; { zone_id = cloudflare_zone.schnerring_net.id name = &#34;k8s&#34; type = &#34;A&#34; value = data.kubernetes_service.traefik.status.0.load_balancer.0.ingress.0.ip proxied = true } How awesome is that?
Step 6: Deploy a Demo Application #  We are almost at the finish line. All that is missing is reaping the fruit of our hard labor. To create a simple demo, we will use the nginxdemos/hello image and make it available at https://hello.k8s.schnerring.net/.
To make it happen, we add a kubernetes_namespace, kubernetes_deployment, kubernetes_service, and kubernetes_ingress resource to a new hello.tf file:
resource &#34;kubernetes_namespace&#34; &#34;hello&#34; { metadata { name = &#34;hello&#34; } } resource &#34;kubernetes_deployment&#34; &#34;hello&#34; { metadata { name = &#34;hello-deploy&#34; namespace = kubernetes_namespace.hello.metadata.0.name labels = { app = &#34;hello&#34; } } spec { replicas = 2 selector { match_labels = { app = &#34;hello&#34; } } template { metadata { labels = { app = &#34;hello&#34; } } spec { container { image = &#34;nginxdemos/hello&#34; name = &#34;hello&#34; port { container_port = 80 } } } } } } resource &#34;kubernetes_service&#34; &#34;hello&#34; { metadata { name = &#34;hello-svc&#34; namespace = kubernetes_namespace.hello.metadata.0.name } spec { selector = { app = kubernetes_deployment.hello.metadata.0.labels.app } port { port = 80 target_port = 80 } } } resource &#34;kubernetes_ingress&#34; &#34;hello&#34; { metadata { name = &#34;hello-ing&#34; namespace = kubernetes_namespace.hello.metadata.0.name annotations = { &#34;cert-manager.io/cluster-issuer&#34; = &#34;letsencrypt-staging&#34; &#34;traefik.ingress.kubernetes.io/router.tls&#34; = &#34;true&#34; } } spec { rule { host = &#34;hello.k8s.schnerring.net&#34; http { path { path = &#34;/&#34; backend { service_name = &#34;hello-svc&#34; service_port = 80 } } } } tls { hosts = [&#34;hello.k8s.schnerring.net&#34;] secret_name = &#34;hello-tls-secret&#34; } } } After running terraform apply again, we should be able to visit the demo site https://hello.k8s.schnerring.net/:
   To verify the HTTPS redirect works, we run curl -svDL http://hello.k8s.schnerring.net (PowerShell), or curl -sLD - http://hello.k8s.schnerring.net (Bash):
... &lt; HTTP/1.1 301 Moved Permanently &lt; Location: https://hello.k8s.schnerring.net/ ... To get rid of the certificate warning, set &quot;cert-manager.io/cluster-issuer&quot; = &quot;letsencrypt-production&quot;. But be aware of rate limits that apply to the Let&rsquo;s Encrypt production API!
One Last Thing #  If we want to tear down the cluster and rebuild, we cannot achieve this in one terraform apply operation. The reason is that the kubernetes-alpha provider requires an operational cluster during the terraform plan phase. On top of that, any CRDs we deploy with the kubernetes-alpha provider have to be available during terraform plan, too.
So when rebuilding, we would first create the AKS cluster and deploy cert-manager and then apply the rest:
terraform destroy -target &#34;azurerm_resource_group.k8s&#34; terraform plan -out infrastructure.tfplan -target &#34;helm_release.cert_manager&#34; terraform apply infrastructure.tfplan terraform plan -out infrastructure.tfplan terraform apply infrastructure.tfplan I already mentioned this earlier. The need for the workaround above originates from stacking Kubernetes cluster infrastructure with Kubernetes resources which the official Kubernetes provider documentation discourages recommend against that. Adhering to the docs and separate cluster and Kubernetes resources into different modules will probably save you a headache!
Other than that, we created a pretty cool solution, fully managed by Terraform, did we not?
You can find all the code on GitHub in my schnerring/infrastructure repository, which is evolving continuously. After committing the code to the repo, I added the v0.1.0 tag. This way, in the future, we can easily find the code depicted in this post.
`}).add({id:9,href:"/posts/create-a-hugo-website-with-github-pages-github-actions-and-cloudflare/",title:"Create a Hugo Website with GitHub Pages, GitHub Actions, and Cloudflare",description:`In this beginner guide, you&rsquo;ll create a Hugo website from scratch and publish the website on GitHub Pages. You&rsquo;ll configure Cloudflare&rsquo;s DNS and utilize its caching capabilities to optimize page speeds. Finally, implementing automated deployments with GitHub Pages will enable you to publish new content on your site easily.
`,content:`In this beginner guide, you&rsquo;ll create a Hugo website from scratch and publish the website on GitHub Pages. You&rsquo;ll configure Cloudflare&rsquo;s DNS and utilize its caching capabilities to optimize page speeds. Finally, implementing automated deployments with GitHub Pages will enable you to publish new content on your site easily.
Motivation #  Over the last couple of years, I&rsquo;ve written documentation for private hobby projects, most of it in Markdown and managed with Git. It&rsquo;s all over the place, some parts quite elaborate, other stuff just bullet point lists.
I think some of it might be useful for others, so I started looking for ways to publish Markdown documentation and found Hugo. It&rsquo;s a simple to use, modern, and very popular static site generator that encourages the use of Markdown files. Perfect!
Having found Hugo, I started looking into how to best host static content. I&rsquo;ve been using GitHub forever, so obviously I chose GitHub Pages. Accompanied by Cloudflare&rsquo;s caching capabilities, a blazingly fast website is guaranteed.
The only thing missing was a way to automagically publish changes made to the Git repository on the website. This is where GitHub Actions come in.
With the technology figured out, in my very first guide, I&rsquo;ll show you step by step how I created this website in its first version. You can check out the code on my GitHub where I tagged the resulting commit with version v1.0.0.
The Plan #  Here is an overview of what you&rsquo;ll do:
 Register for third-party services and install the required software Prepare the Git repository Set up the development environment Create a Hugo site from scratch and run it locally Set up Cloudflare for a custom root (apex) domain Manually deploy the website to GitHub Pages Deploy the website automatically to GitHub Pages with GitHub Actions  I created this guide with Windows users in mind, but the workflow should be easily adaptable to other platforms. The steps are detailed and beginner-friendly, so if you&rsquo;re more experienced, you can skip through most parts of steps 1 to 3.
For this guide, I configured the schnerring.net domain and used schnerring.github.io as the GitHub Pages site. In the instructions, you&rsquo;ll need to replace these accordingly.
Step #1: Prerequisites #  First, you&rsquo;ll need to register for a couple of services and install some software. Everything mentioned is free, except registering a custom domain name. I&rsquo;m not affiliated with any of the products I recommend in this guide.
Sign Up at Third-Party Services #   Register a domain name with your registrar \u2014 I&rsquo;m a very happy Namecheap customer Sign up at Cloudflare Sign up at GitHub  Install Software for Development #  Install the following programs for local development on our workstation:
 Hugo \u2014 make sure to install hugo-extended to be able to use themes that utilize Sass/SCSS Git for Windows \u2014 source control management and shell Visual Studio Code \u2014 editor for coding Google Chrome \u2014 web browser for debugging  I used the Git Bash terminal to create the instructions for this guide. It&rsquo;s bundled with Git for Windows and provides UNIX-like commands like rm, touch, and more.
Step #2: Prepare Git #  Create a GitHub Repository #  Sign in to your GitHub account and create a new repository. To create a user type website with GitHub Pages, name the repository schnerring.github.io.
If you want to know more about GitHub Page types, you can find further information in the GitHub Docs.
Make sure to initialize the repository with a README and a LICENSE file. For this project, I chose the MIT license.
Clone the Newly Created Repository and Open It in VS Code #  If you haven&rsquo;t already, configure an SSH key to use with GitHub. You&rsquo;re now ready to clone the GitHub repository to your workstation. Open a Git Bash terminal and run the following commands:
git clone git@github.com:schnerring/schnerring.github.io.git cd schnerring.github.io code . Step #3: Prepare VS Code #  To make it easier to write clean and consistent code, install the following extensions:
EditorConfig
 EditorConfig helps maintain consistent coding styles for multiple developers working on the same project across various editors and IDEs.
 markdownlint
 markdownlint is a static analysis tool for Node.js with a library of rules to enforce standards and consistency for Markdown files
 shellcheck
 ShellCheck is a GPLv3 tool that gives warnings and suggestions for bash/sh shell scripts
 Add the .vscode/extensions.json File #  Workspace recommended extensions for VS Code make it easy to share a set of extensions easily across development environments. When you open a repository folder in VS Code and some recommended extensions are missing, you&rsquo;ll be notified, and just one click away from installing them.
Here&rsquo;s what the file looks like:
{ &#34;recommendations&#34;: [ &#34;editorconfig.editorconfig&#34;, &#34;davidanson.vscode-markdownlint&#34;, &#34;omartawfik.github-actions-vscode&#34;, &#34;timonwong.shellcheck&#34; ] } Add the .vscode/launch.json File #  When running hugo server locally during development, it&rsquo;s nice to be able to open http://localhost:1313 in Chrome from within VS Code by just hitting the F5 key. For this, you need to add a launch configuration. VS Code stores launch configurations in the launch.json file located in the .vscode/ folder.
For Windows, the configuration looks like this:
{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [ { &#34;type&#34;: &#34;pwa-chrome&#34;, &#34;request&#34;: &#34;launch&#34;, &#34;name&#34;: &#34;Launch Chrome against localhost&#34;, &#34;url&#34;: &#34;http://localhost:1313&#34;, &#34;webRoot&#34;: &#34;\${workspaceFolder}&#34; } ] } Check out the official documentation to learn more about debugging in VS Code.
Add the EditorConfig Configuration #  Add the .editorconfig file to the root folder of the repository:
# top-most EditorConfig file root = true # every file [*] charset = utf-8 indent_size = 2 indent_style = space insert_final_newline = true trim_trailing_whitespace = true # Markdown files [*.md] trim_trailing_whitespace = false Check out EditorConfig if you want to learn more, it&rsquo;s awesome!
Add the .gitignore File #  To prevent cluttering of the repository with files generated by VS Code, add a .gitignore file to the root of the repository. To generate the .gitignore file, I like to use gitignore.io. Hugo adds a debug.log file from time to time which I manually add, as well.
debug.log # Created by https://www.toptal.com/developers/gitignore/api/hugo,vscode # Edit at https://www.toptal.com/developers/gitignore?templates=hugo,vscode ### Hugo ### # Generated files by hugo /public/ /resources/_gen/ hugo_stats.json # Executable may be added to repository hugo.exe hugo.darwin hugo.linux ### vscode ### .vscode/* !.vscode/settings.json !.vscode/tasks.json !.vscode/launch.json !.vscode/extensions.json *.code-workspace # End of https://www.toptal.com/developers/gitignore/api/hugo,vscode Push Development Environment Settings to GitHub #  The folder structure now looks like this:
.vscode/ \u251C\u2500 extensions.json \u251C\u2500 launch.json .editorconfig .gitignore LICENSE README.md Push the changes to GitHub:
git add --all git commit --message=&#34;Add vscode launch.json / extensions.json, .editorconfig, .gitignore&#34; git push Step #4: Enter Hugo #  Only a few steps are required to create a functional Hugo site.
Create a New Site #  To create a Hugo site in your current working folder, use the Hugo CLI:
hugo new site . --force With --force, Hugo won&rsquo;t complain about the folder containing files.
Add a Theme #  To get started quickly, add the Hello Friend theme as a Git Submodule. Check out themes.gohugo.io for more themes.
git submodule add https://github.com/panr/hugo-theme-hello-friend.git themes/hello-friend Update the Hugo Configuration #  The Hello Friend theme requires minimal configuration steps to work. As a baseline, use the sample provided in the themes' README and make some straightforward changes to it.
The resulting config.toml looks like this:
baseURL = &#34;https://schnerring.net&#34; languageCode = &#34;en-us&#34; theme = &#34;hello-friend&#34; paginate = 5 ignoreFiles = [ &#34;LICENSE$&#34; ] [params] # dir name of your blog content (default is \`content/posts\`). # the list of set content will show up on your index page (baseurl). #contentTypeName = &#34;posts&#34; # &#34;light&#34; or &#34;dark&#34; defaultTheme = &#34;dark&#34; # if you set this to 0, only submenu trigger will be visible showMenuItems = 2 # Show reading time in minutes for posts showReadingTime = false # Show table of contents at the top of your posts (defaults to false) # Alternatively, add this param to post front matter for specific posts # toc = true # Show full page content in RSS feed items #(default is Description or Summary metadata in the front matter) # rssFullText = true [languages] [languages.en] title = &#34;Michael Schnerring&#34; subtitle = &#34;Coder and Computer Enthusiast&#34; keywords = &#34;&#34; description = &#34;Michael Schnerring is a coder and computer enthusiast.&#34; copyright = &#34;&lt;p&gt;Copyright \xA9 2020 Michael Schnerring&lt;/p&gt;&lt;p xmlns:dct=&#39;http://purl.org/dc/terms/&#39; xmlns:cc=&#39;http://creativecommons.org/ns#&#39; class=&#39;license-text&#39;&gt;&lt;a rel=&#39;cc:attributionURL&#39; property=&#39;dct:title&#39; href=&#39;https://github.com/schnerring/schnerring.github.io/tree/main/content&#39;&gt;Content&lt;/a&gt; licensed under &lt;a rel=&#39;license&#39; href=&#39;https://creativecommons.org/licenses/by/4.0&#39;&gt;CC BY 4.0&lt;/a&gt;&lt;/p&gt;&#34; menuMore = &#34;Show more&#34; writtenBy = &#34;Written by&#34; readMore = &#34;Read more&#34; readOtherPosts = &#34;Read other posts&#34; newerPosts = &#34;Newer posts&#34; olderPosts = &#34;Older posts&#34; minuteReadingTime = &#34;min read&#34; dateFormatSingle = &#34;2006-01-02&#34; dateFormatList = &#34;2006-01-02&#34; # leave empty to disable, enter display text to enable #lastModDisplay = &#34;modified&#34; [languages.en.params.logo] logoText = &#34;schnerring.net&#34; logoHomeLink = &#34;/&#34; # or # # path = &#34;/img/your-example-logo.svg&#34; # alt = &#34;Your example logo alt text&#34; [languages.en.menu] [[languages.en.menu.main]] identifier = &#34;about&#34; name = &#34;About&#34; url = &#34;/about&#34; The themes' GitHub repository features another config.toml example. You can read more about how to configure Hugo in the official documentation.
Add Some Content #  With the help of the Hugo CLI, add an about page and the first blog post:
hugo new about.md hugo new posts/hello-world.md about.md #  --- title: &#34;About&#34; draft: false --- I code by day and toy around with computers by night... posts/hello-world.md #  --- title: &#34;Hello World&#34; description: &#34;The first post of this blog&#34; date: 2021-03-14T15:00:21+01:00 draft: false tags: - &#34;csharp&#34; - &#34;hello world&#34; --- I&#39;m a .NET developer by trade, so let&#39;s say hello in C#! \`\`\`csharp using System; class Program { public static void Main(string[] args) { Console.WriteLine(&#34;Hello, world!&#34;); } } \`\`\` Note the post&rsquo;s default status draft: true, so newly created content has to be published manually. You can read more about it in the official documentation. Make sure to set this to false before deployment or the post won&rsquo;t be displayed.
Run the Site Locally #  To finally test the changes locally, run the following in a Git Bash terminal. The --buildDrafts (or -D) option enables you to also view content that has set draft: true.
hugo server --buildDrafts Hit the F5 button in VS Code to open the page in Chrome.
Push the Changes #  Git ignores empty folders, so if you push the current changes and re-clone the repository, the Hugo folder structure would be partially gone. A common practice is to add empty .gitkeep marker files to empty folders to prevent this:
touch {data,layouts,static}/.gitkeep Your folder structure should look like this, excluding resources or public folders, since those are .gitignored:
.vscode/ \u251C\u2500 extensions.json \u251C\u2500 launch.json archetypes/ \u251C\u2500 default.md content/ \u251C\u2500 posts/ \u2502 \u251C\u2500 hello-world.md \u251C\u2500 about.md data/ \u251C\u2500 .gitkeep layouts/ \u251C\u2500 .gitkeep static/ \u251C\u2500 .gitkeep themes/ \u251C\u2500 hello-friend/ (submodule) .editorconfig .gitignore .gitmodules config.toml LICENSE README.md Commit and push everything:
git add -A git commit -m &#34;Add Hugo site, hello-friend theme, about page and hello-world post&#34; git push Step #5: Configure Cloudflare #  Add the Site to Cloudflare #   Sign in to your Cloudflare account Click + Add site in the navigation bar and add schnerring.net Select Free plan Navigate to the Overview page of the newly created site Take note of Cloudflare&rsquo;s nameservers, in my case carol.ns.cloudflare.com and cody.ns.cloudflare.com  Change the Nameservers for Your Domain #  Sign in to the administrator account of your domain registrar and change the nameservers. My Namecheap nameserver configuration for schnerring.net looks like this after adding the Cloudflare nameservers:
   Add the CNAME Records #  A CNAME record is used to map one domain name to another. Go to the DNS management at Cloudflare and add the following records to point your domain to GitHub Pages:
   Make sure the \u201Corange cloud\u201D is enabled, so you can define rules and cache static content with Cloudflare.
Enable Full SSL/TLS Encryption Mode #  Go to your site&rsquo;s SSL/TLS settings and set encryption to Full:
   Configure the Browser Cache TTL #  Go to Cache \u2192 Configuration and choose 2 months or higher, depending on how often you think your already published static content changes.
   Add Page Rules #  The Free Tier lets you create up to three page rules. Go to your site&rsquo;s Page Rules settings and click Create Page Rule.
Enforce HTTPS #     Add Forward from www.schnerring.net Subdomain to schnerring.net Root Domain #  If you use a subdomain, skip this step.
   Cache All Static Content to Speed Up the Website #     Page Rules Overview #     Note that as of May 2018 GitHub Pages supports HTTPS for custom domains out of the box. They utilize Let&rsquo;s Encrypt certificates which are better than the shared certificates you get with Cloudflare. But to issue Let&rsquo;s Encrypt certificates for both www.schnerring.net and schnerring.net, you&rsquo;d have to resort this, in my opinion hacky, solution.
Step #6: Deploy the Site to GitHub Pages #  You&rsquo;ll deploy the website to GitHub Pages on a separate, parallel gh-pages branch since published artifacts and source code are segregated this way. You can learn more about other options in the official Hugo documentation.
Initialize gh-pages branch #  Create an orphan branch which has a git init like state with no history:
git checkout --orphan gh-pages git reset --hard git commit --allow-empty -m &#34;Init gh-pages branch&#34; git push origin gh-pages git checkout main Checkout the gh-pages Branch in public/ #  To build the site, use the hugo command. The build artifacts will be placed in the public/ folder, the contents of which need to be published on the gh-pages branch. To be able to checkout multiple branches, use Git&rsquo;s worktree feature:
git worktree add -B gh-pages public origin/gh-pages Add CNAME File to static/ Folder #  Earlier, you configured Cloudflare to properly map www.schnerring.net and schnerring.net to schnerring.github.io&rsquo;s destination. However, you also need a redirect from schnerring.github.io to schnerring.net. You accomplish this by adding a static/CNAME file to the repo, containing your custom domain. When generating the site with hugo, the published site will contain the CNAME file at its root:
echo &#34;schnerring.net&#34; &gt; static/CNAME rm static/.gitkeep git add -A git commit -m &#34;Add CNAME file&#34; git push Build the Hugo Site #  Make sure to set draft: false to publish the hello-world.md post. Push the change to GitHub by running git commit -am &quot;Publish hello-world.md&quot; &amp;&amp; git push.
Then run hugo.
Push the Changes on the gh-pages Branch #  cd public git add -A git commit -m &#34;Publish to gh-pages&#34; git push cd .. Set gh-pages as Publishing Branch #  Navigate to your repository on GitHub
 Go to Settings \u2192 Pages Under Source, select Branch: gh-pages and click Save  It should look like this:
   Shortly after you perform these steps, your website should be available at schnerring.net.
Subsequent Deployments #  For future deployments, several steps are required:
 Delete contents of public/ folder, since hugo does not remove generated files before building Generate the site with hugo Push changes to the gh-pages branch Purge Cloudflare cache  This is an error-prone and tedious process if repeated frequently, so let&rsquo;s automate these steps with GitHub Pages next.
Step #7: Automate Deployments with GitHub Actions #  Configure GitHub Actions #  GitHub Actions Workflows are configured mostly through configuration files in the .github/workflows folder. This allows your configuration to be version controlled and flexible.
Add the following .github/workflows/hugo.yml file to the repository:
name: Hugo on: push: branches: - main # Allows to run workflow manually from Actions tab workflow_dispatch: jobs: build: runs-on: ubuntu-latest steps: - name: Checkout repository and update Hugo themes uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Install Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: &#34;0.81.0&#34; extended: true - name: Build Hugo run: hugo --minify - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v3 with: github_token: \${{ secrets.GITHUB_TOKEN }} publish_dir: ./public - name: Purge Cloudflare Cache env: CLOUDFLARE_ZONE_ID: \${{ secrets.CLOUDFLARE_ZONE_ID }} CLOUDFLARE_API_TOKEN: \${{ secrets.CLOUDFLARE_API_TOKEN }} GITHUB_TOKEN: \${{ secrets.GITHUB_TOKEN }} run: |chmod +x ./purge_cloudflare_cache.sh ./purge_cloudflare_cache.sh Name the GitHub Actions Workflow Hugo which is triggered when pushed to the main branch. As OS, the latest version of ubuntu is used.
We only run one job, build, and perform the following steps:
 Checkout the repository and update Hugo themes Install Hugo extended since the theme uses SCSS. Build Hugo and --minify Deploy to GitHub Pages. The default deployment branch is gh-pages. Choose the ./public folder to be published. Purge the Cloudflare Cache by running the ./purge_cloudflare_cache.sh script that you&rsquo;ll create in the next steps.  The above is straight forward, thanks to the free Actions available at the GitHub Marketplace. Thanks to peaceiris for the awesome work:
 GitHub Actions for Hugo GitHub Actions for GitHub Pages  Note the mapping of the environment variables required in step 4 and 5. You&rsquo;ll later configure the GitHub secrets that will be injected as environment variables into the context of the respective steps. The GITHUB_TOKEN doesn&rsquo;t need to be configured for GitHub Actions, since GitHub automatically creates it to use in your workflow. For local debugging though, you&rsquo;ll have to create a token, anyway.
Create a GitHub Personal Access Token #   Personal access tokens (PAT) are an alternative to using passwords for authentication to GitHub when using the GitHub API or the command line.
 Go to your GitHub profile&rsquo;s Settings \u2192 Developer settings \u2192 Personal access tokens. Click Generate new token, select only the public_repo scope and enter the note schnerring.github.io, to be able to later recognize what it&rsquo;s used for.
You only get one chance to copy the token&rsquo;s value, so add a new environment variable named GITHUB_TOKEN to your local system:
   If you lose the token, just delete and then recreate it.
Create the purge_cloudflare_cache.sh Script #  Purge the Cloudflare Cache #  Use Cloudflare&rsquo;s API to purge all cached files with curl after successful deployment:
curl \\  --silent \\  --request POST \\  --header &#34;Authorization: Bearer \${CLOUDFLARE_API_TOKEN}&#34; \\  --header &#34;Content-Type: application/json&#34; \\  --data &#39;{&#34;purge_everything&#34;:true}&#39; \\  &#34;https://api.cloudflare.com/client/v4/zones/\${CLOUDFLARE_ZONE_ID}/purge_cache&#34; Before you can run the command above, set CLOUDFLARE_ZONE_ID and CLOUDFLARE_API_TOKEN as environment variables in your GitHub repository and your workstation. You can add secrets in your GitHub repository&rsquo;s Settings \u2192 Secrets \u2192 New repository secret:
  Set CLOUDFLARE_ZONE_ID to your Cloudflare site&rsquo;s Zone ID which you can find it on your site&rsquo;s Overview page.
  Set CLOUDFLARE_API_TOKEN to an API Token with Zone.Cache Purge permissions. Create one at My Profile \u2192 API Tokens \u2192 Create Token \u2192 Create Custom Token \u2192 Get started:
     You should then be able to locally run the curl snippet above which should output &quot;success&quot;: true:
{ &#34;result&#34;: { &#34;id&#34;: &#34;********************************&#34; }, &#34;success&#34;: true, &#34;errors&#34;: [], &#34;messages&#34;: [] } Polling the GitHub Pages Build Status #  Before purging the site&rsquo;s cache on Cloudflare, make sure that the GitHub Pages build completed successfully. Via GitHub&rsquo;s API, query the latest GitHub Pages build with curl:
curl \\  --silent \\  --user &#34;schnerring:\${GITHUB_TOKEN}&#34; \\  --header &#34;Accept: application/vnd.github.v3+json&#34; \\  &#34;https://api.github.com/repos/schnerring/schnerring.github.io/pages/builds/latest&#34; The GITHUB_TOKEN you configured earlier is used here. Executing the snippet locally will output &quot;status&quot;: &quot;built&quot; if the GitHub Pages build succeeded:
{ &#34;url&#34;: &#34;https://api.github.com/repos/schnerring/schnerring.github.io/pages/builds/123456789&#34;, &#34;status&#34;: &#34;built&#34;, &#34;error&#34;: { &#34;message&#34;: null }, ... } Put It All Together #  #!/usr/bin/env bash  readonly DELAY_STEP_SECONDS=15 readonly INTERVAL_SECONDS=5 readonly TIMEOUT_SECONDS=120 readonly GITHUB_USER=schnerring readonly GITHUB_REPO=schnerring.github.io ################################################## # Poll status of latest GitHub Pages build every INTERVAL_SECONDS seconds for up # to TIMEOUT_SECONDS seconds. # Globals: # GITHUB_REPO # GITHUB_TOKEN # GITHUB_USER # INTERVAL_SECONDS # TIMEOUT_SECONDS # Arguments: # None # Outputs: # Success message to stdout or error message to stderr. # Returns: # 0 on success, 1 otherwise. ################################################## function poll_build_status() { echo &#34;Awaiting completion of latest GitHub Pages build ...&#34; local waited_seconds=0 while [[ &#34;\${waited_seconds}&#34; -lt &#34;\${TIMEOUT_SECONDS}&#34; ]]; do if curl \\  --silent \\  --user &#34;\${GITHUB_USER}:\${GITHUB_TOKEN}&#34; \\  --header &#34;Accept: application/vnd.github.v3+json&#34; \\  &#34;https://api.github.com/repos/\${GITHUB_USER}/\${GITHUB_REPO}/pages/builds/latest&#34; \\  | grep -q &#39;&#34;status&#34;: &#34;built&#34;&#39;; then echo &#34;Success.&#34; return 0 fi echo &#34; Sleeping \${INTERVAL_SECONDS}seconds until next status poll ...&#34; sleep &#34;\${INTERVAL_SECONDS}&#34; (( waited_seconds += INTERVAL_SECONDS )) done echo &#34;Failure.&#34; &gt;&amp;2 return 1 } ################################################## # Purge entire Cloudflare cache. # Globals: # CLOUDFLARE_API_TOKEN # CLOUDFLARE_ZONE_ID # Arguments: # None # Outputs: # Success message to stdout or error message to stderr. # Returns: # 0 on success, 1 otherwise. ################################################## function purge_cache() { echo &#34;Purging Cloudflare cache ...&#34; if curl \\  --silent \\  --request POST \\  --header &#34;Authorization: Bearer \${CLOUDFLARE_API_TOKEN}&#34; \\  --header &#34;Content-Type: application/json&#34; \\  --data &#39;{&#34;purge_everything&#34;:true}&#39; \\  &#34;https://api.cloudflare.com/client/v4/zones/\${CLOUDFLARE_ZONE_ID}/purge_cache&#34; \\  | grep -q &#39;&#34;success&#34;: true&#39;; then echo &#34;Success.&#34; return 0 else echo &#34;Failure.&#34; &gt;&amp;2 return 1 fi } ################################################## # Main function of script. # Globals: # DELAY_STEP_SECONDS # Arguments: # None ################################################## function main() { echo &#34;Sleeping \${DELAY_STEP_SECONDS}seconds ...&#34; sleep &#34;\${DELAY_STEP_SECONDS}&#34; poll_build_status || exit 1 echo &#34;Sleeping \${DELAY_STEP_SECONDS}seconds ...&#34; sleep &#34;\${DELAY_STEP_SECONDS}&#34; purge_cache || exit 1 } # Entrypoint main &#34;$@&#34; poll_build_status and purge_cache contain the functionality. The main function serves as the entry point executing those functions.
poll_build_status implements a while loop to repeatedly poll GitHub&rsquo;s API. It succeeds if the response contains &quot;status&quot;: &quot;built&quot; or times out after two minutes and fails.
Before each step, the script heuristically sleeps 15 seconds in case of latency issues with GitHub&rsquo;s API or GitHub Pages updates.
Running the ./purge_cloudflare_cache.sh script locally should output:
Awaiting completion of latest GitHub Pages build ... Success. Purging Cloudflare cache ... Success. Note that for sites with lots of files, purging the whole cache should be avoided. Cloudflare supports purging the cache for individual files.
We could list only changed files if we wanted to with a command like git diff-tree -r --no-commit-id --name-only --diff-filter=DM gh-pages and only purge the cache for these files, but that&rsquo;s out of scope for this post.
Now push .github/workflows/hugo.yml and purge_cloudflare_cache.sh to the repository:
git add -A git commit -m &#34;Add .github/workflows/hugo.yml, purge_cloudflare_cache.sh&#34; git push Go check out the Actions tab on your GitHub repository. If everything is configured correctly, GitHub Actions should be building your site:
   After the workflow succeeded, there won&rsquo;t be any changes to the site because we didn&rsquo;t change anything about our site, yet.
To make a change, switch to the light theme by setting defaultTheme = &quot;light&quot; inside the config.toml file. Push the changes by running git commit -am &quot;Set default theme to light&quot; &amp;&amp; git push and another GitHub Action workflow should automatically be triggered.
After the build completes, your website should be displayed in the light theme. If it isn&rsquo;t, make sure to also purge your browser cache.
Wrapping Up #  It took quite a bit of effort, but you now have a hands-off system in place that helps you to publish content to your website in an automated way. All you have to do is pushing new changes to your GitHub repo and after a minute the changes will be live.
`}).add({id:10,href:"/posts/hello-world/",title:"Hello World",description:"The first post of this blog",content:`I&rsquo;m a .NET developer by trade, so let&rsquo;s say hello in C#!
using System; class Program { public static void Main(string[] args) { Console.WriteLine(&#34;Hello, world!&#34;); } } `}),$.addEventListener("input",function(){let r=5,o=this.value,n=e.search(o,r,{enrich:!0}),i=new Map;for(let s of n.flatMap(l=>l.result))i.has(s.href)||i.set(s.doc.href,s.doc);H.innerHTML="",H.classList.remove("search__suggestions--hidden");for(let[s,l]of i){let h=document.createElement("a");h.href=s,h.classList.add("search__suggestion-item"),H.appendChild(h);let m=document.createElement("div");m.textContent=l.title,m.classList.add("search__suggestion-title"),h.appendChild(m);let g=document.createElement("div");if(g.textContent=l.description,g.classList.add("search__suggestion-description"),h.appendChild(g),H.childElementCount===r)break}})})();})();
/*! Source: https://dev.to/shubhamprakash/trap-focus-using-javascript-6a3 */
//! Source: https://discourse.gohugo.io/t/range-length-or-last-element/3803/2
//! Source: https://github.com/h-enk/doks/blob/master/assets/js/index.js
